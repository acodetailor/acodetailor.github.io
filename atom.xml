<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sam</title>
  
  <subtitle>用我的双手，成就你的梦想。一库~</subtitle>
  <link href="https://acodetailor.github.io/atom.xml" rel="self"/>
  
  <link href="https://acodetailor.github.io/"/>
  <updated>2021-09-25T15:05:42.758Z</updated>
  <id>https://acodetailor.github.io/</id>
  
  <author>
    <name>Sam</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Knative</title>
    <link href="https://acodetailor.github.io/2021/09/22/knative%E6%BA%90%E7%A0%81%E4%B8%80/"/>
    <id>https://acodetailor.github.io/2021/09/22/knative%E6%BA%90%E7%A0%81%E4%B8%80/</id>
    <published>2021-09-22T03:25:42.493Z</published>
    <updated>2021-09-25T15:05:42.758Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、Knative是什么"><a href="#一、Knative是什么" class="headerlink" title="一、Knative是什么"></a>一、Knative是什么</h4><p>Knative分为三个部分，Serving、Eventing、Building。<br>Serving：主要使用Knative Service部署应用，具有弹性伸缩等功能。<br>Eventing：事件驱动，通过其他内置的资源，实现事件的异步流转。<br>Building：镜像构建。  </p><h4 id="二、Serving架构"><a href="#二、Serving架构" class="headerlink" title="二、Serving架构"></a>二、Serving架构</h4><p><img src="../../../../image/serverless/serving-crd.jpg" alt="reason">  </p><p>如上图所示，当我们手动创建一个Knative的Service资源时，Knative的controller会自动给我们创建如图所示<br>的资源，实现Serving组件的相关功能。 后续详细分析各个controller代码。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;一、Knative是什么&quot;&gt;&lt;a href=&quot;#一、Knative是什么&quot; class=&quot;headerlink&quot; title=&quot;一、Knative是什么&quot;&gt;&lt;/a&gt;一、Knative是什么&lt;/h4&gt;&lt;p&gt;Knative分为三个部分，Serving、Eventing</summary>
      
    
    
    
    <category term="k8s" scheme="https://acodetailor.github.io/categories/k8s/"/>
    
    
    <category term="knative" scheme="https://acodetailor.github.io/tags/knative/"/>
    
  </entry>
  
  <entry>
    <title>Camelk</title>
    <link href="https://acodetailor.github.io/2021/09/13/camel/"/>
    <id>https://acodetailor.github.io/2021/09/13/camel/</id>
    <published>2021-09-13T15:46:34.407Z</published>
    <updated>2021-09-22T03:25:42.493Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h4><p>Camel这个词想必很多java的开发者都很熟悉了，它是一个开源的集成框架，可以通过它快速的使用第三方的组件、调用其他系统的接口。<br>这篇文章要介绍的camelk，其实是Camel+Knative的组合。<br>通过CRD将Camel的组件封装成k8s集群的资源，CRD Controller创建Knative的Service资源，可以同时使用到Knative带来的弹性伸缩、<br>事件驱动等技术优点。</p><h4 id="二、使用"><a href="#二、使用" class="headerlink" title="二、使用"></a>二、使用</h4><p>下面使用一个例子来进行简单介绍。<br><strong>需求</strong>:<br>通过rest接口提供数据库表的查询。<br><strong>实现</strong>:<br><img src="../../../../image/camelk/camelk-test.jpg" alt="reason"><br><strong>延伸</strong>:<br>实现还是比较简单的，也不需要重新构建发布。延伸看来，我们可以通过这种方式快速实现数据集成、服务暴露等需求。    </p><h4 id="三、架构"><a href="#三、架构" class="headerlink" title="三、架构"></a>三、架构</h4><p><img src="../../../../image/camelk/camelk.png" alt="reason">  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;一、简介&quot;&gt;&lt;a href=&quot;#一、简介&quot; class=&quot;headerlink&quot; title=&quot;一、简介&quot;&gt;&lt;/a&gt;一、简介&lt;/h4&gt;&lt;p&gt;Camel这个词想必很多java的开发者都很熟悉了，它是一个开源的集成框架，可以通过它快速的使用第三方的组件、调用其他系统的</summary>
      
    
    
    
    <category term="k8s" scheme="https://acodetailor.github.io/categories/k8s/"/>
    
    
    <category term="oom" scheme="https://acodetailor.github.io/tags/oom/"/>
    
  </entry>
  
  <entry>
    <title>Serverless之Knative</title>
    <link href="https://acodetailor.github.io/2021/05/16/serverless-istio/"/>
    <id>https://acodetailor.github.io/2021/05/16/serverless-istio/</id>
    <published>2021-05-16T12:59:42.740Z</published>
    <updated>2021-05-16T13:48:47.655Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、什么是Knative"><a href="#一、什么是Knative" class="headerlink" title="一、什么是Knative"></a>一、什么是Knative</h4><p>knative 是谷歌牵头的 serverless 架构方案，旨在提供一套简单易用的 serverless 开源方案，把 serverless 标准化和平台化。目前参与 knative 项目的公司主要有： Google、Pivotal、IBM、Red Hat和SAP。</p><ul><li>这是 Google Cloud Platform 宣布 knative 时给出的介绍：<br><em>Developed in close partnership with Pivotal, IBM, Red Hat, and SAP, Knative pushes Kubernetes-based computing forward by providing the building blocks you need to build and deploy modern, container-based serverless applications.</em><br>与Pivotal，IBM，Red Hat和SAP密切合作开发，通过提供构建和部署基于容器的现代serverless应用程序所需的构建块，Knative推动基于Kubernetes的计算。</li><li>在knative的github页面，Knative 给出的官方介绍如下：<br><em>Kubernetes-based platform to build, deploy, and manage modern serverless workloads.</em><br>基于Kubernetes的平台，用于构建，部署和管理现代serverless工作负载。</li></ul><h4 id="二、Knative概述"><a href="#二、Knative概述" class="headerlink" title="二、Knative概述"></a>二、Knative概述</h4><p>Knative扩展了Kubernetes，提供了一组中间件组件，这些组件对于构建可在任何地方运行的现代以源为中心和基于容器的应用程序至关重要：在本地，在云中，甚至在第三方数据中心。</p><p>Knative项目下的每个组件都尝试识别常见模式并编纂最佳实践，这些最佳实践被真实世界中基于Kubernetes的成功框架和应用程序共享。 Knative组件专注于解决许多平凡但困难的任务，例如：</p><ul><li>部署容器</li><li>在Kubernetes上编排source-to-URL的工作流程</li><li>使用蓝绿部署路由和管理流量</li><li>根据需求自动收缩和调整工作负载大小</li><li>将运行服务绑定到事件生态系统</li></ul><p>Knative的开发人员可以使用熟悉的习语，语言和框架来部署任何工作负载：函数，应用程序或容器。  </p><p><strong>组件</strong></p><ul><li>Build - 源到容器的构建编排</li><li>Eventing - 管理和交付事件</li><li>Serving - 请求驱动的计算，可以扩展到零  </li></ul><p><strong>受众</strong></p><ul><li><p>开发人员<br>Knative组件为开发人员提供Kubernetes原生API，用于将serverless风格的函数，应用程序和容器部署到自动伸缩运行时。</p></li><li><p>运维<br>Knative组件旨在集成到更加优雅的产品中，云服务提供商或大型企业的内部团队可以随后运维。</p></li></ul><p>任何企业或云提供商都可以将Knative组件应用到他们自己的系统中，并将这些收益传递给他们的客户。</p><p>Knative是一个多元化，开放和包容的社区。</p><h4 id="三、Knative优势"><a href="#三、Knative优势" class="headerlink" title="三、Knative优势"></a>三、Knative优势</h4><p>和已有的FaaS/serverless实现不同，knative在产品规划和设计理念上有带来新东西：</p><ul><li><p>工作负载类型<br>和标准化的 FaaS 不同，knative 期望能够运行所有的 workload :</p></li><li><p>traditional application</p></li><li><p>function</p></li><li><p>container</p></li><li><p>针对常见应用用例提供更高级别抽象的聚焦API。</p></li><li><p>在几秒钟内即可提供可扩展，安全，无状态的服务。</p></li><li><p>松耦合特性可以按需使用组件</p></li><li><p>可插拔组件，可以自备日志和监控，网络和服务网格。<br>Knative是可移植的：可运行于Kubernetes运行的任何地方，不用担心供应商锁定。<br>knative 建立在 kubernetes 和 istio 之上</p></li></ul><p>使用 kubernetes 提供的容器管理能力（deployment、replicaset、和 pods等），以及 istio 提供的网络管理功能（ingress、LB、dynamic route等）。</p><p>需要特别强调的是：<strong>knative 是 Kubernetes-based！</strong> 或者说 Kubernetes-only，仅仅运行于k8s平台。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;一、什么是Knative&quot;&gt;&lt;a href=&quot;#一、什么是Knative&quot; class=&quot;headerlink&quot; title=&quot;一、什么是Knative&quot;&gt;&lt;/a&gt;一、什么是Knative&lt;/h4&gt;&lt;p&gt;knative 是谷歌牵头的 serverless 架构方案</summary>
      
    
    
    
    <category term="k8s" scheme="https://acodetailor.github.io/categories/k8s/"/>
    
    
    <category term="k8s" scheme="https://acodetailor.github.io/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>Serverless之Knative流量转发</title>
    <link href="https://acodetailor.github.io/2021/04/30/knative/"/>
    <id>https://acodetailor.github.io/2021/04/30/knative/</id>
    <published>2021-04-30T01:40:25.368Z</published>
    <updated>2021-05-18T07:26:34.581Z</updated>
    
    <content type="html"><![CDATA[<p>前边说过Knative是基于K8s部署的，使用k8s的容器管理功能以及istio的网络管理功能，下边一起看一下Knative的流量是怎么转发的吧。</p><h4 id="一、Knative资源介绍"><a href="#一、Knative资源介绍" class="headerlink" title="一、Knative资源介绍"></a>一、Knative资源介绍</h4><p><strong>Knative资源</strong><br>knative主要分为三个组件，build、server、event，分别处理CI/CD,服务伸缩，事件驱动。<br>流量转发主要由server这部分处理。</p><ul><li>knative service</li><li>knative ingress</li><li>knative serverlessService</li><li>knative route</li><li>knative configuration</li><li>kantive revision  </li></ul><p><strong>istio资源</strong></p><ul><li>Gateway</li><li>virtualService。  </li></ul><h4 id="二、流量转发"><a href="#二、流量转发" class="headerlink" title="二、流量转发"></a>二、流量转发</h4><h5 id="官方架构"><a href="#官方架构" class="headerlink" title="官方架构"></a>官方架构</h5><p>先回顾一下Knative官方的一个简单的原理示意图如下所示。用户创建一个Knative Service（ksvc）后，Knative会自动创建Route（route）、Configuration（cfg）资源，然后cfg会创建对应的Revision（rev）版本。rev实际上又会创建Deployment提供服务，流量最终会根据route的配置，导入到相应的rev中。  </p><p><img src="../../../../image/serverless/serverless.png" alt="reason"></p><h5 id="老版本（0-6）"><a href="#老版本（0-6）" class="headerlink" title="老版本（0.6）"></a>老版本（0.6）</h5><p>在集成使用Istio部署时，Route默认采用的是Istio Ingress Gateway实现，大概在Knative 0.6版本之前，我们可以发现，Route的流量转发本质上是由Istio virtualservice（vs）控制。副本数为0时，其中destination指向的是Activator组件。此时Activator会帮助转发冷启动时的请求。  </p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">route-f8c50d56-3f47-11e9-9a9a-08002715c9e6</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">gateways:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">knative-ingress-gateway</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">mesh</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">helloworld-go.default.example.com</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">helloworld-go.default.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">appendHeaders:</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">Activator-Service.knative-serving.svc.cluster.local</span></span><br><span class="line">        <span class="attr">port:</span></span><br><span class="line">          <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">100</span></span><br></pre></td></tr></table></figure><p>当服务启动后，修改vs将destination指向对应服务实例上。    </p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">uns</span> <span class="string">route-f8c50d56-3f47-11e9-9a9a-08002715c9e6</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"> <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">helloworld-go.default.example.com</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">helloworld-go.default.svc.cluster.local</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">helloworld-go-2xxcn-Service.default.svc.cluster.local</span></span><br><span class="line">        <span class="attr">port:</span></span><br><span class="line">          <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">100</span></span><br></pre></td></tr></table></figure><h5 id="新版本"><a href="#新版本" class="headerlink" title="新版本"></a>新版本</h5><p>我们创建一个简单的hello-go ksvc，并以此进行分析。ksvc如下所示：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">serving.knative.dev/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hello-go</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">faas</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">harbor-yx-jd-dev.yx.netease.com/library/helloworld-go:v0.1</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">TARGET</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;Go Sample v1&quot;</span></span><br></pre></td></tr></table></figure><p>virtualservice的变化<br>环境是一个标准的Istio部署，Serverless网关为Istio Ingress Gateway，所以创建完ksvc后，为了验证服务是否可以正常运行，需要发送http请求至网关。Gateway资源已经在部署Knative的时候创建，这里我们只需要关心vs。在服务副本数为0的时候，Knative控制器创建的vs关键配置如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">gateways:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">knative-serving/cluster-local-gateway</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">knative-serving/knative-ingress-gateway</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hello-go.faas</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hello-go.faas.example.com</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hello-go.faas.svc</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hello-go.faas.svc.cluster.local</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">f81497077928a654cf9422088e7522d5.probe.invalid</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">authority:</span></span><br><span class="line">        <span class="attr">regex:</span> <span class="string">^hello-go\.faas\.example\.com(?::\d&#123;1,5&#125;)?$</span></span><br><span class="line">      <span class="attr">gateways:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">knative-serving/knative-ingress-gateway</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">authority:</span></span><br><span class="line">        <span class="attr">regex:</span> <span class="string">^hello-go\.faas(\.svc(\.cluster\.local)?)?(?::\d&#123;1,5&#125;)?$</span></span><br><span class="line">      <span class="attr">gateways:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">knative-serving/cluster-local-gateway</span></span><br><span class="line">    <span class="attr">retries:</span></span><br><span class="line">      <span class="attr">attempts:</span> <span class="number">3</span></span><br><span class="line">      <span class="attr">perTryTimeout:</span> <span class="string">10m0s</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">hello-go-fpmln.faas.svc.cluster.local</span></span><br><span class="line">        <span class="attr">port:</span></span><br><span class="line">          <span class="attr">number:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>vs指定了已经创建好的gw，同时destination指向的是一个Service域名。这个Service就是Knative默认自动创建的hello-go服务的Service。<br>可以发现vs的ownerReferences指向了一个Knative的CRD ingress.networking.internal.knative.dev：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ownerReferences:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">networking.internal.knative.dev/v1alpha1</span></span><br><span class="line">  <span class="attr">blockOwnerDeletion:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">controller:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hello-go</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="string">4a27a69e-5b9c-11ea-ae53-fa163ec7c05f</span></span><br></pre></td></tr></table></figure><p>根据名字可以看到这是一个Knative内部使用的CRD，该CRD的内容其实和vs比较类似，同时ingress.networking.internal.knative.dev的ownerReferences指向了我们熟悉的route，总结下来就是：<br>route -&gt; kingress(ingress.networking.internal.knative.dev) -&gt; vs<br>在网关这一层涉及到的CRD资源就是如上这些。这里kingress的意义在于增加一层抽象，如果我们使用的是其他网关，则会将kingress转换成相应的网关资源配置。最新的版本中，负责kingress到Istio vs的控制器部分代码已经独立出一个项目，可见如今的Knative对Istio已经不是强依赖。<br>现在，我们已经了解到Serverless网关是由Knative控制器最终生成的vs生效到Istio Ingress Gateway上，为了验证我们刚才部署的服务是否可以正常的运行，简单的用curl命令试验一下。</p><p>和所有的网关或者负载均衡器一样，对于7层http访问，我们需要在Header里加域名Host，用于流量转发到具体的服务。在上面的vs中已经可以看到对外域名和内部Service域名均已经配置。所以，只需要：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -v -H<span class="string">&#x27;Host:hello-go.faas.example.com&#x27;</span>  &lt;IngressIP&gt;:&lt;Port&gt; </span><br></pre></td></tr></table></figure><p>其中，IngressIP即网关实例对外暴露的IP。</p><p>对于冷启动来说，目前的Knative需要等十几秒，即会收到请求。根据之前老版本的经验，这个时候vs会被更新，destination指向hello-go的Service。</p><p>不过，现在我们实际发现，vs没有任何变化，仍然指向了服务的Service。对比老版本中服务副本数为0时，其实vs的destination指向的是Activator组件的。但现在，不管服务副本数如何变化，vs一直不变。</p><p>蹊跷只能从destination的Service域名入手。</p><p>revision service探索<br>创建ksvc后，Knative会帮我们自动创建Service如下所示。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n faas get svc</span><br><span class="line">NAME                     TYPE           CLUSTER-IP     EXTERNAL-IP                                            PORT(S)      </span><br><span class="line">hello-go                 ExternalName   &lt;none&gt;         cluster-local-gateway.istio-system.svc.cluster.local   &lt;none&gt;           </span><br><span class="line">hello-go-fpmln           ClusterIP      10.178.4.126   &lt;none&gt;                                                 80/TCP             </span><br><span class="line">hello-go-fpmln-m9mmg     ClusterIP      10.178.5.65    &lt;none&gt;                                                 80/TCP,8022/TCP  </span><br><span class="line">hello-go-fpmln-metrics   ClusterIP      10.178.4.237   &lt;none&gt;                                                 9090/TCP,9091/TCP</span><br></pre></td></tr></table></figure><p>hello-go Service是一个ExternalName Service，作用是将hello-go的Service域名增加一个dns CNAME别名记录，指向网关的Service域名。</p><p>根据Service的annotation我们可以发现，Knative对hello-go-fpmln、hello-go-fpmln-m9mmg 、hello-go-fpmln-metrics这三个Service的定位分别为public Service、private Service和metric Service（最新版本已经将private和metrics Service合并）。</p><p>private Service和metric Service其实不难理解。问题的关键就在这里的public Service，仔细研究hello-go-fpmln Service，我们可以发现这是一个没有labelSelector的Service，它的Endpoint不是kubernetes自动创建的，需要额外生成。</p><p>在服务副本数为0时，查看一下Service对应的Endpoint，如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n faas get ep</span><br><span class="line">NAME                     ENDPOINTS                               AGE</span><br><span class="line">hello-go-fpmln           172.31.16.81:8012                       </span><br><span class="line">hello-go-fpmln-m9mmg     172.31.16.121:8012,172.31.16.121:8022   </span><br><span class="line">hello-go-fpmln-metrics   172.31.16.121:9090,172.31.16.121:9091   </span><br></pre></td></tr></table></figure><p>其中，public Service的Endpoint IP是Knative Activator的Pod IP，实际发现Activator的副本数越多这里也会相应的增加。并且由上面的分析可以看到，vs的destination指向的就是public Service。</p><p>输入几次curl命令模拟一下http请求，虽然副本数从0开始增加到1了，但是这里的Endpoint却没有变化，仍然为Activator Pod IP。</p><p>接着使用hey来压测一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./hey_linux_amd64 -n 1000000 -c 300  -m GET -host helloworld-go.faas.example.com http://&lt;IngressIP&gt;:80</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>发现Endpoint变化了，通过对比服务的Pod IP，已经变成了新启动的服务Pod IP，不再是Activator Pod的IP。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n faas get ep</span><br><span class="line">NAME                     ENDPOINTS                         </span><br><span class="line">helloworld-go-mpk25      172.31.16.121:8012</span><br><span class="line">hello-go-fpmln-m9mmg     172.31.16.121:8012,172.31.16.121:8022   </span><br><span class="line">hello-go-fpmln-metrics   172.31.16.121:9090,172.31.16.121:9091 </span><br></pre></td></tr></table></figure><p>原来，现在新版本的冷启动流量转发机制已经不再是通过修改vs来改变网关的流量转发配置了，而是直接更新服务的public Service后端Endpoint，从而实现将流量从Activator转发到实际的服务Pod上。</p><p>通过将流量的转发功能内聚到Service/Endpoint层，一方面减小了网关的配置更新压力，一方面Knative可以在对接各种不同的网关时的实现时更加解耦，网关层不再需要关心冷启动时的流量转发机制。</p><p>流量路径<br>再深入从上述的三个Service入手研究，它们的ownerReference是serverlessservice.networking.internal.knative.dev(sks)，而sks的ownerReference是podautoscaler.autoscaling.internal.knative.dev(kpa)。</p><p>在压测过程中同样发现，sks会在冷启动过后，会从Proxy模式变为Serve模式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n faas get sks</span><br><span class="line">NAME             MODE    SERVICENAME      PRIVATESERVICENAME     READY   REASON</span><br><span class="line">hello-go-fpmln   Proxy   hello-go-fpmln   hello-go-fpmln-m9mmg   True</span><br><span class="line">$ kubectl -n faas get sks</span><br><span class="line">NAME             MODE    SERVICENAME      PRIVATESERVICENAME     READY   REASON</span><br><span class="line">hello-go-fpmln   Serve   hello-go-fpmln   hello-go-fpmln-m9mmg   True</span><br></pre></td></tr></table></figure><p>这也意味着，当流量从Activator导入的时候，sks为Proxy模式，服务真正启动起来后会变成Serve模式，网关流量直接流向服务Pod。</p><p>从名称上也可以看到，sks和kpa均为Knative内部CRD，实际上也是由于Knative设计上可以支持自定义的扩缩容方式和支持Kubernetes HPA有关，实现更高一层的抽象。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;前边说过Knative是基于K8s部署的，使用k8s的容器管理功能以及istio的网络管理功能，下边一起看一下Knative的流量是怎么转发的吧。&lt;/p&gt;
&lt;h4 id=&quot;一、Knative资源介绍&quot;&gt;&lt;a href=&quot;#一、Knative资源介绍&quot; class=&quot;head</summary>
      
    
    
    
    <category term="k8s" scheme="https://acodetailor.github.io/categories/k8s/"/>
    
    
    <category term="knative" scheme="https://acodetailor.github.io/tags/knative/"/>
    
  </entry>
  
  <entry>
    <title>Serverless之介绍</title>
    <link href="https://acodetailor.github.io/2021/04/28/serverless/"/>
    <id>https://acodetailor.github.io/2021/04/28/serverless/</id>
    <published>2021-04-28T06:35:10.932Z</published>
    <updated>2021-05-20T01:08:34.408Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、Serverless是什么"><a href="#一、Serverless是什么" class="headerlink" title="一、Serverless是什么"></a>一、Serverless是什么</h4><p>Serverless ，按中文翻译，称为「无服务器」。<br>这究竟是一种什么样的形态或产品呢？无服务器，就是真的没有服务器吗？<br>实际并不是没有服务器，只是用户只是不用更多的去考虑服务器的相关内容了，无需再去考虑服务器的规格大小、存储类型、网络带宽、自动扩缩容的问题。</p><h4 id="二、Serverless的发展"><a href="#二、Serverless的发展" class="headerlink" title="二、Serverless的发展"></a>二、Serverless的发展</h4><p><img src="../../../../image/serverless/developer.png" alt="developer"><br><img src="../../../../image/serverless/arrow.png" alt="arrow"></p><p><strong>Serverless</strong>通常是指FaaS和BaaS：<br><strong>Functions-as-a-Service (FaaS)</strong> ，通常提供事件驱动计算。开发人员使用由事件或HTTP请求触发的function来运行和管理应用程序代码。<br><strong>Backend-as-a-Service (BaaS)</strong> ，它是基于API的第三方服务，可替代应用程序中的核心功能子集。例如数据库、对象存储等第三方服务。</p><h4 id="三、Serverless的技术特点："><a href="#三、Serverless的技术特点：" class="headerlink" title="三、Serverless的技术特点："></a>三、Serverless的技术特点：</h4><h5 id="1、事件驱动"><a href="#1、事件驱动" class="headerlink" title="1、事件驱动"></a>1、事件驱动</h5><ul><li>云函数的运行，是由事件驱动起来的，在有事件到来时，云函数会启动运行</li><li>Serverless 应用不会类似于原有的「监听 - 处理」类型的应用一直在线，而是按需启动</li><li>事件的定义可以很丰富，一次 http 请求，一个文件上传，一次数据库条目修改，一条消息发送，都可以定义为事件  </li></ul><p><img src="../../../../image/serverless/event.png" alt="event"></p><h5 id="2、单事件处理"><a href="#2、单事件处理" class="headerlink" title="2、单事件处理"></a>2、单事件处理</h5><ul><li>云函数由事件触发，而触发启动的一个云函数实例，一次仅处理一个事件</li><li>无需在代码内考虑高并发高可靠性，代码可以专注于业务，开发更简单</li><li>通过云函数实例的高并发能力，实现业务高并发  </li></ul><p><img src="../../../../image/serverless/single.png" alt="single"></p><h5 id="3、自动弹性伸缩"><a href="#3、自动弹性伸缩" class="headerlink" title="3、自动弹性伸缩"></a>3、自动弹性伸缩</h5><ul><li>由于云函数事件驱动及单事件处理的特性，云函数通过自动的伸缩来支持业务的高并发</li><li>针对业务的实际事件或请求数，云函数自动弹性合适的处理实例来承载实际业务量</li><li>在没有事件或请求时，无实例运行，不占用资源  </li></ul><p><img src="../../../../image/serverless/autoscale.png" alt="autoscale"></p><h5 id="4、无状态开发"><a href="#4、无状态开发" class="headerlink" title="4、无状态开发"></a>4、无状态开发</h5><ul><li>云函数运行时根据业务弹性，可能伸缩到 0，无法在运行环境中保存状态数据</li><li>分布式应用开发中，均需要保持应用的无状态，以便于水平伸缩</li><li>可以利用外部服务、产品，例如数据库或缓存，实现状态数据的保存  </li></ul><p><img src="../../../../image/serverless/nostate.png" alt="nostate"></p><h4 id="四、业界的Serverless产品"><a href="#四、业界的Serverless产品" class="headerlink" title="四、业界的Serverless产品"></a>四、业界的Serverless产品</h4><h5 id="1、谷歌云-function"><a href="#1、谷歌云-function" class="headerlink" title="1、谷歌云 function"></a>1、谷歌云 function</h5><p><strong>GoogleCloud function产品优势介绍</strong>  </p><p>利用可伸缩的函数即服务 (FaaS) 运行代码，随用随付，并且无需执行任何服务器管理工作。</p><ul><li>不必预配、管理或升级服务器</li><li>根据负载自动扩缩</li><li>集成式监控、日志记录和调试功能</li><li>基于最小权限原则的角色和函数级别的内置安全性</li><li>适用于混合云和多云端方案的关键网络功能  </li></ul><p><strong>GoogleCloud产品界面</strong>  </p><ul><li><strong>函数列表</strong><br><img src="../../../../image/serverless/googlecloud01.png" alt="googlecloud02"></li><li><strong>创建函数，配置HTTP触发器暴露对应的函数</strong><br><img src="../../../../image/serverless/googlecloud01.png" alt="googlecloud02"></li></ul><h5 id="2、AWS"><a href="#2、AWS" class="headerlink" title="2、AWS"></a>2、AWS</h5><p>AWS拥有和Google function类似的产品，叫做lambda.</p><ul><li><strong>lambda函数列表</strong><br><img src="../../../../image/serverless/aws01.png" alt="aws01"></li><li><strong>配置HTTP触发器暴lambda露函数</strong><br><img src="../../../../image/serverless/aws02.png" alt="aws01">  </li></ul><h5 id="3、阿里云"><a href="#3、阿里云" class="headerlink" title="3、阿里云"></a>3、阿里云</h5><p>阿里云也有自己的Serverless产品，分别是函数计算和Serverless工作流，函数计算和Google的function，AWS的lambda基本一样，不多做介绍了。  </p><p>下边看一下Serverless工作流这个产品。<br>在Serverless工作流中，用户可以通过yaml来编排函数，事件会按照工作流的定义，流转工作流中的服务，以实现一定的业务逻辑，创建页面如下图  </p><p><img src="../../../../image/serverless/aliyun01.png" alt="aws01">  </p><h5 id="4、海尔智家PSI"><a href="#4、海尔智家PSI" class="headerlink" title="4、海尔智家PSI"></a>4、海尔智家PSI</h5><p>我们PSI也有一款Serverless产品，目前已上线事件驱动流程功能，配合工单通知业务，已落地生产。<br>同步函数计算功能，正在迭代中，近期就会上线，敬请期待。</p><ul><li><strong>产品主界面：</strong>  </li></ul><p><img src="../../../../image/serverless/haier01.png" alt="haier01">  </p><ul><li><strong>事件流程界面：</strong>  </li></ul><p>事件流程通过流程图的形式编排服务，更加直观、易懂。<br><img src="../../../../image/serverless/haier02.png" alt="haier01">   </p><p><strong>PSI Serverless产品体验地址</strong>：<a href="https://edgy.haier.net/">https://edgy.haier.net</a><br><strong>PSI Serverless产品文档地址</strong>：<a href="https://edgy.haier.net/doc">https://edgy.haier.net/doc</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;一、Serverless是什么&quot;&gt;&lt;a href=&quot;#一、Serverless是什么&quot; class=&quot;headerlink&quot; title=&quot;一、Serverless是什么&quot;&gt;&lt;/a&gt;一、Serverless是什么&lt;/h4&gt;&lt;p&gt;Serverless ，按中文翻译，</summary>
      
    
    
    
    <category term="k8s" scheme="https://acodetailor.github.io/categories/k8s/"/>
    
    
    <category term="k8s" scheme="https://acodetailor.github.io/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>java的OOM问题</title>
    <link href="https://acodetailor.github.io/2021/04/24/java_oom/"/>
    <id>https://acodetailor.github.io/2021/04/24/java_oom/</id>
    <published>2021-04-24T12:11:36.499Z</published>
    <updated>2021-04-28T06:34:43.262Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、一些概念"><a href="#一、一些概念" class="headerlink" title="一、一些概念"></a>一、一些概念</h4><p>JVM中的堆被划分为两个不同区域：新生代Young、老年代Old。新生代又划分为Eden(伊甸，标志新生)， Survivor0(s0)， Survivor(s1)。<br>JVM中堆的GC分为：Minor GC 和 Full GC(又称为Major GC)</p><p>年轻代<br>年轻代用于存放新创建的对象，存储大小默认为堆大小的1/15，特点是对象更替速度快，即短时间内产生大量的“死亡对象”<br>-Xmn 可以设置年轻代为固定大小<br>-XX:NewRatio 可以设置年轻代与老年代的大小比例<br>年轻代使用复制-清除算法和并行收集器进行垃圾回收，对年轻代的垃圾回收称为初级回收（minor GC)<br>minor GC 将年轻代分为三个区域，一个Eden, 两个大小相同的Survivor。应用程序只能同时使用一个Eden和一个活动Survivor, 另外一个Survivor为非活动Survivor（两个Survivor在活动与非活动间交替存在，即同一时刻只存在一个活动Survivor和一个非活动Survivor）。<br>当发生 minor GC时：JVM执行下述操作</p><ol><li>将程序挂起</li><li>将Eden和活动Survivor中的存活对象（存活对象指的是仍被引用的对象）复制到另一个非活动的Survivor中（记录对象被复制到另一个Survivor的次数，在此称为年龄数，每次复制+1）</li><li>清除Eden和活动Survivor中对象</li><li>将非活动Survivor标记为活动，将原来的活动Survivor标记为非活动<br>上述即为一轮 minor GC 结束<br>如此往复多次 minor GC后，将多次被复制的对象（高龄对象）移动到老年代中<br>默认被移动到老年代的年龄为15，可以通过参数 -XX:MaxTenuring Threshold 来设置。<br>当然，对于一些占用较大内存的对象，会被直接送入老年代</li></ol><p>老年代<br>老年代存储的是那些不会轻易“死掉”的对象，毕竟都在年轻代中熬出了头。<br>在老年代发生的GC成为 Full GC 。Full GC 不会像 Minor GC那么频繁<br>Full GC 采用 标记-清除算法 收集垃圾的时候会产生许多内存碎片（不连续的存储空间），因此此后若有较大的对象要进入老年代而无法找到适合的存储空间，就会提前触发一次GC收集，对内存空间进行整理</p><p>永久代<br>永久代（Perm Gen）是JDK7中的特性，JDK8后被取消。永久区是JVM方法区的实现方式之一，JDK8起，被元空间（与堆不相连的本地空间）取而代之<br>永久代存放的是应用元数据（应用中使用的类和方法），永久代中的对象在 Full GC 的时候进行垃圾回收</p><p>简单来讲，jvm的内存回收过程是这样的：<br>对象在Eden Space创建，当Eden Space满了的时候，gc就把所有在Eden Space中的对象扫描一次，把所有有效的对象复制到第一个Survivor Space，同时把无效的对象所占用的空间释放。当Eden Space再次变满了的时候，就启动移动程序把Eden Space中有效的对象复制到第二个Survivor Space，同时，也将第一个Survivor Space中的有效对象复制到第二个Survivor Space。如果填充到第二个Survivor Space中的有效对象被第一个Survivor Space或Eden Space中的对象引用，那么这些对象就是长期存在的，此时这些对象将被复制到Permanent Generation。</p><p>若垃圾收集器依据这种小幅度的调整收集不能腾出足够的空间，就会运行Full GC，此时jvm gc停止所有在堆中运行的线程并执行清除动作。</p><h4 id="二、优化配置"><a href="#二、优化配置" class="headerlink" title="二、优化配置"></a>二、优化配置</h4><p>-Xms 是指程序启动时初始内存大小（此值可以设置成与-Xmx相同，以避免每次GC完成后 JVM 内存重新分配）。默认为物理内存的1/64，最小为1M；可以指定单位，比如k、m，若不指定，则默认为字节。<br>-Xmx 指程序运行时最大可用内存大小，程序运行中内存大于这个值会 OutOfMemory。默认为物理内存的1/4或者1G，最小为2M；单位与-Xms一致<br>-Xmn 年轻代大小（整个JVM内存大小 = 年轻代 + 年老代 + 永久代）。<br>-XX:NewRatio 年轻代与年老代的大小比例，-XX:NewRatio=4 设置为4，则年轻代与年老代所占比值为1：4。<br>-XX:SurvivorRatio 年轻代中Eden区与Survivor区的大小比值，-XX:SurvivorRatio=4，设置为4，则两个Survivor区与一个Eden区的比值为 2:4<br>-XX:MaxPermSize 设置永久代大小。<br>-XX:MaxTenuringThreshold 设置垃圾最大年龄。<br>如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。<br>-Xss 设置每个线程的堆栈大小。默认为512k</p><h4 id="三、容器化场景配置使用容器内存大小，避免Cgroup的oom"><a href="#三、容器化场景配置使用容器内存大小，避免Cgroup的oom" class="headerlink" title="三、容器化场景配置使用容器内存大小，避免Cgroup的oom"></a>三、容器化场景配置使用容器内存大小，避免Cgroup的oom</h4><p>JDK 8u131 在 JDK 9 中有一个特性，可以在 Docker 容器运行时能够检测到多少内存的能力。<br>在容器内部运行 JVM，它在大多数情况下将如何默认最大堆为主机内存的1/4，而非容器内存的1/4。如果对 Java 容器中的jvm虚拟机不做任何限制，<br>当我们同时运行几个 java 容器时，很容易导致服务器的内存耗尽、负载飙升而宕机；而如果我们对容器直接进行限制，就会导致内核在某个时候杀死<br>jvm 容器而导致频繁重启。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -m 100MB openjdk:8u121 java -XshowSettings:vm -version</span><br><span class="line">VM settings:</span><br><span class="line">    Max. Heap Size (Estimated): 444.50M</span><br><span class="line">    Ergonomics Machine Class: server</span><br><span class="line">    Using VM: OpenJDK 64-Bit Server VM</span><br></pre></td></tr></table></figure><p>下面我们尝试 JDK 8u131 中的实验性参数 -XX:+UseCGroupMemoryLimitForHeap</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -m 100MB openjdk:8u131 java \</span><br><span class="line">  -XX:+UnlockExperimentalVMOptions \</span><br><span class="line">  -XX:+UseCGroupMemoryLimitForHeap \</span><br><span class="line">  -XshowSettings:vm -version</span><br><span class="line">VM settings:</span><br><span class="line">    Max. Heap Size (Estimated): 44.50M</span><br><span class="line">    Ergonomics Machine Class: server</span><br><span class="line">    Using VM: OpenJDK 64-Bit Server VM</span><br></pre></td></tr></table></figure><p>JVM能够检测容器只有100MB，并将最大堆设置为44M。</p><p>下面尝试一个更大的容器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -m 1GB openjdk:8u131 java \</span><br><span class="line">  -XX:+UnlockExperimentalVMOptions \</span><br><span class="line">  -XX:+UseCGroupMemoryLimitForHeap \</span><br><span class="line">  -XshowSettings:vm -version</span><br><span class="line">VM settings:</span><br><span class="line">    Max. Heap Size (Estimated): 228.00M</span><br><span class="line">    Ergonomics Machine Class: server</span><br><span class="line">    Using VM: OpenJDK 64-Bit Server VM</span><br></pre></td></tr></table></figure><p>嗯，现在容器有1GB，但JVM仅使用228M作为最大堆。</p><p>除了JVM正在容器中运行以外，我们是否还可以优化它呢？</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -m 1GB openjdk:8u131 java \</span><br><span class="line">  -XX:+UnlockExperimentalVMOptions \</span><br><span class="line">  -XX:+UseCGroupMemoryLimitForHeap \</span><br><span class="line">  -XX:MaxRAMFraction=1 -XshowSettings:vm -version</span><br><span class="line">VM settings:</span><br><span class="line">    Max. Heap Size (Estimated): 910.50M</span><br><span class="line">    Ergonomics Machine Class: server</span><br><span class="line">    Using VM: OpenJDK 64-Bit Server VM</span><br></pre></td></tr></table></figure><p>使用-XX:MaxRAMFraction 我们告诉JVM使用可用内存/ MaxRAMFraction作为最大堆。使用-XX:MaxRAMFraction=1我们几乎所有可用的内存作为最大堆。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;一、一些概念&quot;&gt;&lt;a href=&quot;#一、一些概念&quot; class=&quot;headerlink&quot; title=&quot;一、一些概念&quot;&gt;&lt;/a&gt;一、一些概念&lt;/h4&gt;&lt;p&gt;JVM中的堆被划分为两个不同区域：新生代Young、老年代Old。新生代又划分为Eden(伊甸，标志新生)，</summary>
      
    
    
    
    <category term="运维" scheme="https://acodetailor.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="oom" scheme="https://acodetailor.github.io/tags/oom/"/>
    
  </entry>
  
  <entry>
    <title>Minikube搭建istio和Knative</title>
    <link href="https://acodetailor.github.io/2021/04/19/install%20knative/"/>
    <id>https://acodetailor.github.io/2021/04/19/install%20knative/</id>
    <published>2021-04-19T09:26:51.731Z</published>
    <updated>2021-04-28T06:32:58.096Z</updated>
    
    <content type="html"><![CDATA[<p>需要搭建一套knative的测试环境，但是没有测试集群可以用了，就用自己的电脑搭建了一个测试环境。搭建过程记录一下</p><h4 id="环境信息"><a href="#环境信息" class="headerlink" title="环境信息"></a>环境信息</h4><p>os:Mac<br>Driver:VirtualBox</p><h4 id="搭建minikube"><a href="#搭建minikube" class="headerlink" title="搭建minikube"></a>搭建minikube</h4><p>一条命令即可,可以指定cpu和内存–cpus int  –memory int</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">minikube start --vm-driver=virtualbox --image-repository=<span class="string">&#x27;registry.cn-hangzhou.aliyuncs.com/google_containers&#x27;</span></span><br></pre></td></tr></table></figure><p>minikube常用命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">1. minikube start启动minikube</span><br><span class="line">2. minikube dashboard 打开dashboard</span><br><span class="line">3. minikube version查看minikube版本</span><br><span class="line">4. minikube status 查看集群状态</span><br><span class="line">5. minikube ip 显示虚拟机ip地址</span><br><span class="line">6. minikube stop  停止虚拟机</span><br><span class="line">7. minikube ssh  ssh到虚拟机中</span><br><span class="line">8. minikube  delete 删除虚拟机</span><br><span class="line">9. minikube logs查看虚拟机日志</span><br><span class="line">10. minikube update-check 检查更新</span><br><span class="line">11. minikube node list[add|start|stop|delete] 对节点进行操作</span><br><span class="line">12. minikube mount 将指定的目录挂载到minikube</span><br><span class="line">13. minikube docker-env  配置环境以使用minikube的docker守护进程</span><br><span class="line">14. minikube podman-env  配置环境以使用minikube的Podman服务</span><br><span class="line">15. minikube cache 添加，删除，或推送一个本地映像到minikube</span><br><span class="line">16. minikube addons 启用或禁用一个minikube插件</span><br><span class="line">17. minikube config  修改持久化配置值</span><br><span class="line">18. minikube  profile  获取或者列出当前的配置文件（集群）</span><br><span class="line">19. minikube update-context  在IP或者端口改变的情况下更新kubeconfig</span><br></pre></td></tr></table></figure><p>安装成功后提示如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">😄  Darwin 10.14.6 上的 minikube v1.8.2</span><br><span class="line">✨  根据现有的配置文件使用 virtualbox 驱动程序</span><br><span class="line">✅  正在使用镜像存储库 registry.cn-hangzhou.aliyuncs.com/google_containers</span><br><span class="line">💾  Downloading preloaded images tarball <span class="keyword">for</span> k8s v1.17.3 ...</span><br><span class="line">⌛  重新配置现有主机</span><br><span class="line">🏃  Using the running virtualbox <span class="string">&quot;minikube&quot;</span> VM ...</span><br><span class="line">🐳  正在 Docker 19.03.6 中准备 Kubernetes v1.17.3…</span><br><span class="line">🚀  正在启动 Kubernetes ... </span><br><span class="line">🌟  Enabling addons: default-storageclass, storage-provisioner</span><br><span class="line">🏄  完成！kubectl 已经配置至 <span class="string">&quot;minikube&quot;</span></span><br></pre></td></tr></table></figure><h4 id="搭建istio"><a href="#搭建istio" class="headerlink" title="搭建istio"></a>搭建istio</h4><p>下载istio的包，然后根据提示配置环境变量，由于某些已知原因，可以配置host</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">199.232.28.133 raw.githubusercontent.com</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -L https://istio.io/downloadIstio | ISTIO_VERSION=1.9.1 TARGET_ARCH=x86_64 sh -</span><br></pre></td></tr></table></figure><p>安装命令：根据需要选择合适的profile</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">istioctl manifest apply --<span class="built_in">set</span> profile=demo //使用这条命令安装失败了。</span><br><span class="line">istioctl install --<span class="built_in">set</span> profile=demo -y</span><br></pre></td></tr></table></figure><p>追加部署addons</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> istio-1.9.1</span><br><span class="line">kc  --context=minikube apply -f samples/addons -n istio-system</span><br></pre></td></tr></table></figure><h4 id="搭建knative"><a href="#搭建knative" class="headerlink" title="搭建knative"></a>搭建knative</h4><p>knative搭建比较简单，可以手动安装，再麻烦一点，可以自己下载yaml手动执行，serving和eventing一共四个yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">serving-crds</span><br><span class="line">serving-core</span><br><span class="line">eventing-crds</span><br><span class="line">eventing-core</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply --filename <span class="string">&quot;https://github.com/knative/serving/releases/download/v0.17.0/serving-crds.yaml&quot;</span></span><br></pre></td></tr></table></figure><p>比较麻烦的是镜像，国内无法直接下载到，可以手动下载后，使用minikube cache 添加到minikube的节点上。</p><h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><p><img src="../../../../image/install/knative.png" alt="reason"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;需要搭建一套knative的测试环境，但是没有测试集群可以用了，就用自己的电脑搭建了一个测试环境。搭建过程记录一下&lt;/p&gt;
&lt;h4 id=&quot;环境信息&quot;&gt;&lt;a href=&quot;#环境信息&quot; class=&quot;headerlink&quot; title=&quot;环境信息&quot;&gt;&lt;/a&gt;环境信息&lt;/h4&gt;</summary>
      
    
    
    
    <category term="k8s" scheme="https://acodetailor.github.io/categories/k8s/"/>
    
    
    <category term="k8s" scheme="https://acodetailor.github.io/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>记一次OOM的问题排查</title>
    <link href="https://acodetailor.github.io/2021/04/12/ops-oom/"/>
    <id>https://acodetailor.github.io/2021/04/12/ops-oom/</id>
    <published>2021-04-12T13:03:40.025Z</published>
    <updated>2021-04-28T06:34:43.266Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、问题现象"><a href="#一、问题现象" class="headerlink" title="一、问题现象"></a>一、问题现象</h1><ul><li>三天前，业务的pod重启了，业务想知道具体原因。</li></ul><p><img src="../../../../image/problem/0412/%E4%B8%9A%E5%8A%A1%E6%97%A5%E5%BF%97.png" alt="reason"></p><h1 id="二、排查记录"><a href="#二、排查记录" class="headerlink" title="二、排查记录"></a>二、排查记录</h1><ul><li>首先排查kubelet日志，蛋疼的是期间业务手动重启了几次，导致不知道pod重启时所在的节点。<br>一个个节点排查kubelet的日志（不知道后续有没有好的方法），找到节点发现日志如下：</li></ul><p><img src="../../../../image/problem/0412/kubelet%E6%97%A5%E5%BF%97.png" alt="reason"></p><p>  kubelet执行PLEG时发现容器挂掉了，直接给拉起了，就是业务前台发现的重启事件。</p><ul><li>再排查业务日志，发现只有Killed,八成是OOM了。日志截图如下：</li></ul><p><img src="../../../../image/problem/0412/%E6%9C%8D%E5%8A%A1%E6%97%A5%E5%BF%97.png" alt="reason"></p><ul><li>下一步排查内核日志，kerenal。发现确实是OOM了。截图如下:</li></ul><p><img src="../../../../image/problem/0412/cgroup%E6%97%A5%E5%BF%97.png" alt="reason"></p><ul><li>然后问题来了，我们的监控发现并没有达到内存的上限，但是cgroup确实达到了上限。真是让人头大啊。</li></ul><h1 id="三、几个命令"><a href="#三、几个命令" class="headerlink" title="三、几个命令"></a>三、几个命令</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zgrep <span class="string">&quot;&quot;</span> *.gz</span><br><span class="line">journalctl --since <span class="string">&#x27;2021-04-09 22:00&#x27;</span></span><br></pre></td></tr></table></figure><h1 id="四、引申问题"><a href="#四、引申问题" class="headerlink" title="四、引申问题"></a>四、引申问题</h1><ul><li>1、cgroup的机制</li><li>2、java的内存机制</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、问题现象&quot;&gt;&lt;a href=&quot;#一、问题现象&quot; class=&quot;headerlink&quot; title=&quot;一、问题现象&quot;&gt;&lt;/a&gt;一、问题现象&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;三天前，业务的pod重启了，业务想知道具体原因。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=</summary>
      
    
    
    
    <category term="运维" scheme="https://acodetailor.github.io/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="oom" scheme="https://acodetailor.github.io/tags/oom/"/>
    
  </entry>
  
  <entry>
    <title>记一次超级坑的问题排查</title>
    <link href="https://acodetailor.github.io/2021/04/09/problem/"/>
    <id>https://acodetailor.github.io/2021/04/09/problem/</id>
    <published>2021-04-09T06:37:26.865Z</published>
    <updated>2021-11-03T09:41:05.778Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、问题描述"><a href="#一、问题描述" class="headerlink" title="一、问题描述"></a>一、问题描述</h4><p><strong>问题①：</strong><br>之前开发了一个功能，通过页面初始化gitlab代码脚手架，周一来想新建一个工程时，创建失败。gitlab仓库初始化成功，每次创建了一个文件时就失败了。</p><p><strong>问题②：</strong><br>问题①解决后，线上流水线打包失败，提示net/http包要求go 1.17而我们用的是1.13.</p><h4 id="二、排查过程"><a href="#二、排查过程" class="headerlink" title="二、排查过程"></a>二、排查过程</h4><p><strong>问题①：</strong><br>本地debug，发现每次在gitlab创建文件时，第一个文件会初始化成功，但是第二个就会报400。没有其他的报错信息。考虑到gitlab刚升级了版本，所以自然的怀疑是升级引入的bug。比如新版做了限流等。<br><strong>1、</strong>找到gitlab服务端的容器，gitlab是裸docker单独部署的。进入容器后查看nginx的access、error日志、gitlab自己的production.log api_json.log。<br>production.log中记录了第一次创建成功的记录，state:200。<br>api_json.log中发现了失败的记录。state:400。 和接口一样没有任何有用的提示。<br><strong>2、</strong>查看gitlab的change.log也没发现相关信息。<br>最后本地提交代码时想起来，别的组的同事给gitlab加了个钩子函数，校验commit信息的格式，比如符合”任务号 操作 信息”的格式。怀疑是这里引起的，修改代码的commit信息。<br>run ok。 解决~<br><strong>问题②：</strong><br>问题①解决后，提交代码，流水线打包失败。提示go的net/http包引用了最新的版本，需要升级go的版本。但是本地run和build都没有问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;go&#x2F;pkg&#x2F;mod&#x2F;golang.org&#x2F;x&#x2F;net@v0.0.0-20211029224645-99673261e6eb&#x2F;http2&#x2F;transport.go:417:45: undefined: os.ErrDeadlineExceeded</span><br><span class="line">note: module requires Go 1.17</span><br></pre></td></tr></table></figure><p>我只改了一行字符串格式的代码，所以当时以为是流水线出了问题，看了一下打包日志，也没发现问题。让负责流水线的同事排查了。 最后反馈只有我的工程出现问题了。这就很头疼了，接着排查吧。可以发现这个出问题的包是10.29 release的，三天前<br><strong>思考方向：</strong><br>Q1：我引的包没有固定版本号，默认下载的最新的？<br>A1：查看go.mod后发现没有。<br>Q2：我间接引用的包没有固定版本号，导致下载了最新的包？<br>A2：这个就很头疼了，要一个个包排查吗？ 想起使用go mod graph可以查看所有依赖关系，本地执行后发现没问题，这也和上边提到的本地没问题。<br>Q3：github的issue看一下有没有类似的？<br>A3：发现了几个issue和我遇到的问题一样，但是member认为不是bug，已经close了。<br><a href="https://github.com/golang/go/issues/45950#issuecomment-833054056%E3%80%81">https://github.com/golang/go/issues/45950#issuecomment-833054056、</a><br><a href="https://github.com/golang/go/issues/45946#issuecomment-832236587">https://github.com/golang/go/issues/45946#issuecomment-832236587</a><br>Q4：怀疑基础镜像被改了，导致的问题？<br>A4：查看基础镜像历史，发现并没改。<br>Q5：再去看看之前成功和失败的打包日志，结果发现了一个之前成功的日志里也会去拉latest的包，我以为就是我间接引用的包出了问题，一顿吐槽。<br>然后再去打包机器上看详细的失败日志，一个可疑的日志出现了。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go get: upgraded golang.org/x/net v0.0.0-20201110031124-69a78807bb2b =&gt; v0.0.0-20211101193420-4a448f8816b3。</span><br></pre></td></tr></table></figure><p>为什么回去更新包版本呢。难道有go get -u ,去查看dockerfile，发现获取swag的包的时候使用了-u会去更新版本。<br>问题语句：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN go get -u github.com/swaggo/swag/cmd/swag@v1.6.7  </span><br></pre></td></tr></table></figure><p>修改后打包成功。 解决~</p><h4 id="三、心得"><a href="#三、心得" class="headerlink" title="三、心得"></a>三、心得</h4><p>问题①其实别的部门添加这个函数我是知道的，但是没有第一时间想到对自己开发的功能的影响，导致了这个问题。长时间没出问题，导致的松懈。<br>问题②当初dockerfile看了一下没问题，直接从别的工程赋值修改的。没有对每行代码了解清楚，导致了问题。排查方向感觉也有点问题，导致时间浪费。<br>应该先去打包机器看日志，也许解决的就快一些了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;一、问题描述&quot;&gt;&lt;a href=&quot;#一、问题描述&quot; class=&quot;headerlink&quot; title=&quot;一、问题描述&quot;&gt;&lt;/a&gt;一、问题描述&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;问题①：&lt;/strong&gt;&lt;br&gt;之前开发了一个功能，通过页面初始化gitlab代码脚手架，</summary>
      
    
    
    
    <category term="problem" scheme="https://acodetailor.github.io/categories/problem/"/>
    
    
    <category term="problem" scheme="https://acodetailor.github.io/tags/problem/"/>
    
  </entry>
  
  <entry>
    <title>k8s clientSet</title>
    <link href="https://acodetailor.github.io/2021/04/09/golang/"/>
    <id>https://acodetailor.github.io/2021/04/09/golang/</id>
    <published>2021-04-09T06:37:13.851Z</published>
    <updated>2021-11-03T09:44:18.887Z</updated>
    
    <content type="html"><![CDATA[<h4 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h4><p>今天看了一下公司内部CMDB通过SDK暴露接口的代码，结构体十分抽象，看的我有点晕。所以想到了k8s的clientset，就想学习一下，提升一下自己的代码。<br>Do things that are easier to understand, not easier to do。</p><h4 id="二、分析过程"><a href="#二、分析过程" class="headerlink" title="二、分析过程"></a>二、分析过程</h4><p>1、首先要获得根据config来创建各个资源组的client，用来和apiserver交互。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">func NewForConfig(c *rest.Config) (*Clientset, error) &#123;</span><br><span class="line">configShallowCopy :&#x3D; *c</span><br><span class="line">if configShallowCopy.RateLimiter &#x3D;&#x3D; nil &amp;&amp; configShallowCopy.QPS &gt; 0 &#123;</span><br><span class="line">if configShallowCopy.Burst &lt;&#x3D; 0 &#123;</span><br><span class="line">return nil, fmt.Errorf(&quot;burst is required to be greater than 0 when RateLimiter is not set and QPS is set to greater than 0&quot;)</span><br><span class="line">&#125;</span><br><span class="line">configShallowCopy.RateLimiter &#x3D; flowcontrol.NewTokenBucketRateLimiter(configShallowCopy.QPS, configShallowCopy.Burst)</span><br><span class="line">&#125;</span><br><span class="line">var cs Clientset</span><br><span class="line">var err error</span><br><span class="line">cs.admissionregistrationV1, err &#x3D; admissionregistrationv1.NewForConfig(&amp;configShallowCopy)</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">return nil, err</span><br><span class="line">&#125;</span><br><span class="line">cs.admissionregistrationV1beta1, err &#x3D; admissionregistrationv1beta1.NewForConfig(&amp;configShallowCopy)</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">return nil, err</span><br><span class="line">&#125;</span><br><span class="line">cs.internalV1alpha1, err &#x3D; internalv1alpha1.NewForConfig(&amp;configShallowCopy)</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">return nil, err</span><br><span class="line">&#125;</span><br><span class="line">cs.appsV1, err &#x3D; appsv1.NewForConfig(&amp;configShallowCopy)</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">return nil, err</span><br><span class="line">&#125;</span><br><span class="line">     ...&#x2F;&#x2F;重复代码，省略。</span><br><span class="line">cs.DiscoveryClient, err &#x3D; discovery.NewDiscoveryClientForConfig(&amp;configShallowCopy)</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">return nil, err</span><br><span class="line">&#125;</span><br><span class="line">return &amp;cs, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">type Clientset struct &#123;</span><br><span class="line">*discovery.DiscoveryClient</span><br><span class="line">admissionregistrationV1      *admissionregistrationv1.AdmissionregistrationV1Client</span><br><span class="line">admissionregistrationV1beta1 *admissionregistrationv1beta1.AdmissionregistrationV1beta1Client</span><br><span class="line">internalV1alpha1             *internalv1alpha1.InternalV1alpha1Client</span><br><span class="line">appsV1                       *appsv1.AppsV1Client</span><br><span class="line">....&#x2F;&#x2F;各个资源client声明，省略</span><br><span class="line">schedulingV1alpha1           *schedulingv1alpha1.SchedulingV1alpha1Client</span><br><span class="line">schedulingV1beta1            *schedulingv1beta1.SchedulingV1beta1Client</span><br><span class="line">schedulingV1                 *schedulingv1.SchedulingV1Client</span><br><span class="line">storageV1beta1               *storagev1beta1.StorageV1beta1Client</span><br><span class="line">storageV1                    *storagev1.StorageV1Client</span><br><span class="line">storageV1alpha1              *storagev1alpha1.StorageV1alpha1Client</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2、然后我们选一个组，如appv1的，client声明如下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appsV1   *appsv1.AppsV1Client</span><br></pre></td></tr></table></figure><p>对应的结构体</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">type AppsV1Client struct &#123;</span><br><span class="line">restClient rest.Interface</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结构体实现了以下方法，实现了该分组下的资源接口的管理</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">func (c *AppsV1Client) ControllerRevisions(namespace string) ControllerRevisionInterface &#123;</span><br><span class="line">return newControllerRevisions(c, namespace)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (c *AppsV1Client) DaemonSets(namespace string) DaemonSetInterface &#123;</span><br><span class="line">return newDaemonSets(c, namespace)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (c *AppsV1Client) Deployments(namespace string) DeploymentInterface &#123;</span><br><span class="line">return newDeployments(c, namespace)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (c *AppsV1Client) ReplicaSets(namespace string) ReplicaSetInterface &#123;</span><br><span class="line">return newReplicaSets(c, namespace)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (c *AppsV1Client) StatefulSets(namespace string) StatefulSetInterface &#123;</span><br><span class="line">return newStatefulSets(c, namespace)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以deployment为例子，DeploymentInterface包含了deployment资源的所有方法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">type DeploymentInterface interface &#123;</span><br><span class="line">Create(ctx context.Context, deployment *v1.Deployment, opts metav1.CreateOptions) (*v1.Deployment, error)</span><br><span class="line">Update(ctx context.Context, deployment *v1.Deployment, opts metav1.UpdateOptions) (*v1.Deployment, error)</span><br><span class="line">UpdateStatus(ctx context.Context, deployment *v1.Deployment, opts metav1.UpdateOptions) (*v1.Deployment, error)</span><br><span class="line">Delete(ctx context.Context, name string, opts metav1.DeleteOptions) error</span><br><span class="line">DeleteCollection(ctx context.Context, opts metav1.DeleteOptions, listOpts metav1.ListOptions) error</span><br><span class="line">Get(ctx context.Context, name string, opts metav1.GetOptions) (*v1.Deployment, error)</span><br><span class="line">List(ctx context.Context, opts metav1.ListOptions) (*v1.DeploymentList, error)</span><br><span class="line">Watch(ctx context.Context, opts metav1.ListOptions) (watch.Interface, error)</span><br><span class="line">Patch(ctx context.Context, name string, pt types.PatchType, data []byte, opts metav1.PatchOptions, subresources ...string) (result *v1.Deployment, err error)</span><br><span class="line">Apply(ctx context.Context, deployment *appsv1.DeploymentApplyConfiguration, opts metav1.ApplyOptions) (result *v1.Deployment, err error)</span><br><span class="line">ApplyStatus(ctx context.Context, deployment *appsv1.DeploymentApplyConfiguration, opts metav1.ApplyOptions) (result *v1.Deployment, err error)</span><br><span class="line">GetScale(ctx context.Context, deploymentName string, options metav1.GetOptions) (*autoscalingv1.Scale, error)</span><br><span class="line">UpdateScale(ctx context.Context, deploymentName string, scale *autoscalingv1.Scale, opts metav1.UpdateOptions) (*autoscalingv1.Scale, error)</span><br><span class="line"></span><br><span class="line">DeploymentExpansion</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就可以通过如下类似builder模式来调用，感觉还是很简洁、清楚的。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.AppsV1().Deployments(<span class="string">&quot;test&quot;</span>).List(ctx,opts)</span><br></pre></td></tr></table></figure><p><strong>每次读k8s的代码都有收获！</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;一、背景&quot;&gt;&lt;a href=&quot;#一、背景&quot; class=&quot;headerlink&quot; title=&quot;一、背景&quot;&gt;&lt;/a&gt;一、背景&lt;/h4&gt;&lt;p&gt;今天看了一下公司内部CMDB通过SDK暴露接口的代码，结构体十分抽象，看的我有点晕。所以想到了k8s的clientset，就</summary>
      
    
    
    
    <category term="k8s" scheme="https://acodetailor.github.io/categories/k8s/"/>
    
    
    <category term="k8s" scheme="https://acodetailor.github.io/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>terraform cloud CLI</title>
    <link href="https://acodetailor.github.io/2021/04/07/terraform_cloud/"/>
    <id>https://acodetailor.github.io/2021/04/07/terraform_cloud/</id>
    <published>2021-04-07T02:02:39.990Z</published>
    <updated>2021-04-28T06:34:43.256Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h1><ul><li>terraform自身提供可一个机制（类似CI/CD的流水线），可以配置自己的git库，根据git库文件内容的变化，执行<br>plan、apply，也可以手动执行。以及配置变量文件、环境变量、state文件统一存储等等功能。</li></ul><h1 id="二、对比"><a href="#二、对比" class="headerlink" title="二、对比"></a>二、对比</h1><p>1、使用terraform二进制。</p><ul><li>需要下载provider(terraform init)</li><li>编写tf文件，backend存储。也需要统一的配置管理。</li><li>每次手动触发。  </li></ul><p>2、使用Cloud CLI。</p><ul><li>不需要准备provider</li><li>统一的配置管理</li><li>git push后即触发 terraform</li></ul><h1 id="三、栗子"><a href="#三、栗子" class="headerlink" title="三、栗子"></a>三、栗子</h1><h4 id="1、创建组织"><a href="#1、创建组织" class="headerlink" title="1、创建组织"></a>1、创建组织</h4><ul><li>terraform网站创建即可。 <a href="https://app.terraform.io/">https://app.terraform.io</a><h4 id="2、配置git库"><a href="#2、配置git库" class="headerlink" title="2、配置git库"></a>2、配置git库</h4></li><li>可以使用个人的git库，配置Oauth权限。根据提示 在github-&gt;setting-&gt;developer settings-&gt; oauth apps申请配置即可。  </li></ul><h4 id="3、选择工程"><a href="#3、选择工程" class="headerlink" title="3、选择工程"></a>3、选择工程</h4><ul><li>git新建一个工程，然后再terraform处选择该工程。  </li></ul><p><img src="../../../../image/terraform/terraformcloud.jpg" alt="chooserepo"></p><h4 id="4、测试"><a href="#4、测试" class="headerlink" title="4、测试"></a>4、测试</h4><ul><li>执行Run即可，每次修改都会触发 plan,然后需要手动执行apply。  </li></ul><h4 id="5、结果"><a href="#5、结果" class="headerlink" title="5、结果"></a>5、结果</h4><p><img src="../../../../image/terraform/terraformapply.jpg" alt="apply"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、简介&quot;&gt;&lt;a href=&quot;#一、简介&quot; class=&quot;headerlink&quot; title=&quot;一、简介&quot;&gt;&lt;/a&gt;一、简介&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;terraform自身提供可一个机制（类似CI/CD的流水线），可以配置自己的git库，根据git库文件内容的变</summary>
      
    
    
    
    <category term="terraform" scheme="https://acodetailor.github.io/categories/terraform/"/>
    
    
    <category term="terraform" scheme="https://acodetailor.github.io/tags/terraform/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes CRD -- kubebuilder搭建</title>
    <link href="https://acodetailor.github.io/2021/04/02/k8s_crd/"/>
    <id>https://acodetailor.github.io/2021/04/02/k8s_crd/</id>
    <published>2021-04-02T02:17:18.350Z</published>
    <updated>2021-04-28T06:34:43.250Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>官方解释：CustomResourceDefinition API 资源允许你定义定制资源。 定义 CRD 对象的操作会使用你所设定的名字和模式定义（Schema）<br>创建一个新的定制资源， Kubernetes API 负责为你的定制资源提供存储和访问服务。 CRD 对象的名称必须是合法的 DNS 子域名。</p><p>DNS子域名规则如下：</p><ul><li>不能超过253个字符</li><li>只能包含小写字母、数字，以及’-‘ 和 ‘.’</li><li>须以字母数字开头</li><li>须以字母数字结尾</li></ul><p>简单来说，你可以定义像k8s原生资源如deployment、service一样定义自己的资源，而k8s会为你提供存储（ETCD）,访问（kube-apiserver）。</p><h1 id="脚手架"><a href="#脚手架" class="headerlink" title="脚手架"></a>脚手架</h1><p>kubebuilder 和 operator sdk, 个人只使用过kubebuilder。</p><h1 id="安装kubebuilder"><a href="#安装kubebuilder" class="headerlink" title="安装kubebuilder"></a>安装kubebuilder</h1><h3 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h3><p>1、docker<br>2、go 建议版本在1.12以上，支持 go mod<br>3、kustomize</p><h3 id="代理配置"><a href="#代理配置" class="headerlink" title="代理配置"></a>代理配置</h3><p>配置一下 终端代理，因为初始化时会拉去go的依赖包。<br>go 1.12之下开启 go module</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> GOPROXY=https://goproxy.io</span><br><span class="line"><span class="built_in">export</span> GO111MODULE=on</span><br></pre></td></tr></table></figure><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p><strong>一、安装kubebuilder</strong><br>执行如下命令。（如果curl下载失败，大概率是网络原因，可以手动下载，解压到指定目录）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">os= $(go env GOOS)</span><br><span class="line">arch=$(go env GOARCH)</span><br><span class="line">curl -L https://go.kubebuilder.io/dl/2.3.1/<span class="variable">$&#123;os&#125;</span>/<span class="variable">$&#123;arch&#125;</span> | tar -xz -C /tmp/</span><br><span class="line">sudo mv /tmp/kubebuilder_2.3.1_<span class="variable">$&#123;os&#125;</span>_<span class="variable">$&#123;arch&#125;</span> /usr/<span class="built_in">local</span>/kubebuilder</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/usr/<span class="built_in">local</span>/kubebuilder/bin</span><br></pre></td></tr></table></figure><p><strong>二、安装kustomize</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install kustomize </span><br></pre></td></tr></table></figure><p><strong>三、安装完成后查看版本信息</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubebuilder version</span><br><span class="line">Version: version.Version&#123;KubeBuilderVersion:<span class="string">&quot;2.3.1&quot;</span>, KubernetesVendor:<span class="string">&quot;1.16.4&quot;</span>, GitCommit:<span class="string">&quot;8b53abeb4280186e494b726edf8f54ca7aa64a49&quot;</span>, BuildDate:<span class="string">&quot;2020-03-26T16:42:00Z&quot;</span>, GoOs:<span class="string">&quot;unknown&quot;</span>, GoArch:<span class="string">&quot;unknown&quot;</span>&#125;</span><br><span class="line"><span class="comment"># sam @ MacBook-Pro-2 in ~/tf/alitest [10:45:37]</span></span><br><span class="line">$ kustomize version</span><br><span class="line">&#123;Version:kustomize/v3.8.2 GitCommit:e2973f6ecc9be6187cfd5ecf5e180f842249b3c6 BuildDate:2020-09-02T07:01:55+01:00 GoOs:darwin GoArch:amd64&#125;</span><br></pre></td></tr></table></figure><p><strong>四、初始化工程</strong>  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubebuilder init --domain my.crd.com  //初始化工程</span><br><span class="line">kubebuilder create api --group custom --version v1 --kind Unit //生成脚手架代码</span><br></pre></td></tr></table></figure><p> <strong>group</strong>: 比如资源文件的apps/v1, apps即为分组，还有其他extensions、cores等。  </p><p> <strong>version</strong>: 顾名思义、v1即为版本。  </p><p> <strong>kind</strong>: API “顶级”资源对象的类型，每个资源对象都需要 Kind 来区分它自身代表的资源类型。比如 pod,deployment.  </p><p> <strong>resource</strong>: 通过 HTTP 协议以 JSON 格式发送或者读取的资源展现形式，可以以单个资源对象展现。  </p><p> <strong>GVK(group、version、kind)</strong>:<br>同 Kind 不止可以出现在同一分组的不同版本中，如 apps/v1beta1 与 apps/v1，它还可能出现在不同的分组中，例如 Deployment 开始以 alpha 的特性出现在 extensions 分组，GA 之后被推进到 apps 组，所以为了严格区分不同的 Kind，需要组合 API Group、API Version 与 Kind 成为 GVK。  </p><p> <strong>GVR(group、version、resource)</strong>:<br>GVR 常用于组合成 RESTful API 请求路径。例如，针对应用程序 v1 部署的 RESTful API 请求如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /apis/apps/v1/namespaces/&#123;namespace&#125;/deployments/&#123;name&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;概念&quot;&gt;&lt;a href=&quot;#概念&quot; class=&quot;headerlink&quot; title=&quot;概念&quot;&gt;&lt;/a&gt;概念&lt;/h1&gt;&lt;p&gt;官方解释：CustomResourceDefinition API 资源允许你定义定制资源。 定义 CRD 对象的操作会使用你所设定的名字和</summary>
      
    
    
    
    <category term="k8s" scheme="https://acodetailor.github.io/categories/k8s/"/>
    
    
    <category term="k8s" scheme="https://acodetailor.github.io/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>Terraform介绍</title>
    <link href="https://acodetailor.github.io/2021/03/30/terraform/"/>
    <id>https://acodetailor.github.io/2021/03/30/terraform/</id>
    <published>2021-03-30T02:38:39.714Z</published>
    <updated>2021-04-28T06:34:43.270Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介："><a href="#简介：" class="headerlink" title="简介："></a>简介：</h2><p>Terraform是IT 基础架构自动化编排工具，它的口号是 “Write,Plan, and create Infrastructure as Code”, 基础架构即代码。</p><p>怎么理解这句话，我们先假设在没有Terraform的年代我们是怎么操作云服务。</p><p>方式一：直接登入到云平台的管控页面，人工点击按钮、键盘敲入输入参数的方式来操作，这种方式对于单个或几个云服务器还可以维护的过来，但是当云服务规模达到几十几百甚至上千以后，明显这种方式对于人力来说变得不再现实，而且容易误操作。</p><p>方式二：云平台提供了各种SDK，将对云服务的操作拆解成一个个的API供使用厂商通过代码来调用。这种方式明显好于方式一，使大批量操作变得可能，而且代码测试通过后可以避免人为误操作。但是随之带来的问题是厂商们需要专业的开发人员（Java、Python、Php、Ruby等），而且对复杂云平台的操作需要写大量的代码。</p><p>方式三：云平台提供了命令行操作云服务的工具，例如AWS CLI，这样租户厂商不再需要软件开发人员就可以实现对平台的命令操作。命令就像Sql一样，使用增删改查等操作元素来管理云。</p><p>方式四：Terraform主角登场，如果说方式三中CLI是命令式操作，需要明确的告知云服务本次操作是查询、新增、修改、还是删除，那么Terraform就是目的式操作，在本地维护了一份云服务状态的模板，模板编排成什么样子的，云服务就是什么样子的。对比方式三的优势是我们只需要专注于编排结果即可，不需要关心用什么命令去操作。</p><p>Terraform的意义在于，通过同一套规则和命令来操作不同的云平台（包括私有云）。</p><h2 id="Terraform知识准备："><a href="#Terraform知识准备：" class="headerlink" title="Terraform知识准备："></a>Terraform知识准备：</h2><p>核心文件有2个，一个是编排文件，一个是状态文件</p><p>main.tf文件：是业务编排的主文件，定制了一系列的编排规则，后面会有详细介绍。</p><p>terraform.tfstate：本地状态文件，相当于本地的云服务状态的备份，会影响terraform的执行计划。</p><p>如果本地状态与云服务状态不一样时会怎样？</p><p>这个大家不需要担心，前面介绍过Terraform是目的式的编排，会按照预设结果完成编排并最终同步更新本地文件。</p><p>Provider：Terraform定制的一套接口，跟OpenStack里Dirver、Java里Interface的概念是一样的，阿里云、AWS、私有云等如果想接入进来被Terraform编排和管理就要实现一套Provider，而这些实现对于Terraform的顶层使用者来说是无感知的。</p><p>Module：可以理解为provider的集合，完成一个完整的功能。</p><h2 id="相关命令："><a href="#相关命令：" class="headerlink" title="相关命令："></a>相关命令：</h2><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>初始化本地环境，下载provider,校验terraform版本等.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ terraform init              //自动下载最新的provider</span><br><span class="line">$ terraform init -plugin-dir  //指定provider目录</span><br></pre></td></tr></table></figure><h2 id="plan"><a href="#plan" class="headerlink" title="plan"></a>plan</h2><p>比较云端资源和本地state资源.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ terraform plan</span><br></pre></td></tr></table></figure><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>将修改部署到云端资源.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ terraform apply</span><br></pre></td></tr></table></figure><h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h2><p>将云端资源删除.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ terraform destory</span><br></pre></td></tr></table></figure><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>创建阿里云用户组、资源组并且配置只读权限。<br>注: alicloud : 阿里云provider名字，不能修改。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">provider <span class="string">&quot;alicloud&quot;</span> &#123;</span><br><span class="line">   access_key = <span class="string">&quot;*******************&quot;</span></span><br><span class="line">   secret_key = <span class="string">&quot;*************************&quot;</span></span><br><span class="line">   region = <span class="string">&quot;cn-beijing&quot;</span></span><br><span class="line"> &#125;</span><br><span class="line"> resource <span class="string">&quot;alicloud_ram_group&quot;</span> <span class="string">&quot;group&quot;</span> &#123;</span><br><span class="line">   name     = <span class="string">&quot;test_group_1000&quot;</span></span><br><span class="line">   force    = <span class="literal">true</span></span><br><span class="line"> &#125;</span><br><span class="line"> resource <span class="string">&quot;alicloud_ram_group_policy_attachment&quot;</span> <span class="string">&quot;attach&quot;</span> &#123;</span><br><span class="line">   policy_name = <span class="string">&quot;ReadOnlyAccess&quot;</span></span><br><span class="line">   policy_type = <span class="string">&quot;System&quot;</span></span><br><span class="line">   group_name  = alicloud_ram_group.group.name</span><br><span class="line"> &#125;</span><br><span class="line"> resource <span class="string">&quot;alicloud_resource_manager_resource_group&quot;</span> <span class="string">&quot;example&quot;</span> &#123;</span><br><span class="line">   resource_group_name = <span class="string">&quot;tftest01&quot;</span></span><br><span class="line">   display_name        = <span class="string">&quot;tftest01&quot;</span></span><br><span class="line"> &#125;</span><br><span class="line"> data <span class="string">&quot;alicloud_account&quot;</span> <span class="string">&quot;example&quot;</span> &#123;&#125;</span><br><span class="line"> resource <span class="string">&quot;alicloud_resource_manager_policy_attachment&quot;</span> <span class="string">&quot;example&quot;</span> &#123;</span><br><span class="line">   policy_name       = <span class="string">&quot;ReadOnlyAccess&quot;</span></span><br><span class="line">   policy_type       = <span class="string">&quot;System&quot;</span></span><br><span class="line">   principal_name    = format(<span class="string">&quot;%s@group.%s.onaliyun.com&quot;</span>, alicloud_ram_group.group.name, data.alicloud_account.example.id)</span><br><span class="line">   principal_type    = <span class="string">&quot;IMSGroup&quot;</span></span><br><span class="line">   resource_group_id = alicloud_resource_manager_resource_group.example.id</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>1、配置terraform自动补全</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ terraform -install-autocomplete</span><br></pre></td></tr></table></figure><p>2、查看terraform的日志</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> TF_LOG=TRACE</span><br><span class="line">$ <span class="built_in">export</span> TF_LOG_PATH=/var/<span class="built_in">log</span>/terraform.log</span><br></pre></td></tr></table></figure><p>3、terraform 通过配置文件或者环境变量进行配置<br>文件目录(自己创建)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="variable">$HOME</span>/.terraformrc </span><br></pre></td></tr></table></figure><p>环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ os.Setenv(<span class="string">&quot;TF_PLUGIN_CACHE_DIR&quot;</span>, <span class="string">&quot;/tmp/provider&quot;</span>) // add provider cache</span><br></pre></td></tr></table></figure><h2 id="state文件存储，支持consul、oss等"><a href="#state文件存储，支持consul、oss等" class="headerlink" title="state文件存储，支持consul、oss等"></a>state文件存储，支持consul、oss等</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">terraform &#123;</span><br><span class="line">  backend <span class="string">&quot;consul&quot;</span> &#123;</span><br><span class="line">    address = <span class="string">&quot;consul.example.com&quot;</span></span><br><span class="line">    scheme  = <span class="string">&quot;https&quot;</span></span><br><span class="line">    path    = <span class="string">&quot;full/path&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">data <span class="string">&quot;terraform_remote_state&quot;</span> <span class="string">&quot;foo&quot;</span> &#123;</span><br><span class="line">  backend = <span class="string">&quot;consul&quot;</span></span><br><span class="line">  config = &#123;</span><br><span class="line">    path = <span class="string">&quot;full/path&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>参考： <a href="https://theithollow.com/2018/05/21/using-hashicorp-consul-to-store-terraform-state/">https://theithollow.com/2018/05/21/using-hashicorp-consul-to-store-terraform-state/</a></p><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><ul><li><p>单行注释以 # 开头</p></li><li><p>多行注释用 /* 和 */ 换行</p></li><li><p>值使用 key = value 的语法分配（空格无关紧要）。该值可以是任何原语（字符串，数字，布尔值），列表或映射。</p></li><li><p>字符串为双引号。</p></li><li><p>字符串可以使用 ${} 包装的语法对其他值进行插值，例如 ${var.foo} 。此处记录了完整的内插语法。</p></li><li><p>多行字符串可以使用外壳样式的“ here doc”语法，该字符串以类似 &lt;&lt;EOF 的标记开头，然后以 EOF 结尾。字符串和结束标志的线路必须不能缩进。</p></li><li><p>假定数字以10为底。如果为数字加上 0x 前缀，则将其视为十六进制数字。</p></li><li><p>布尔值： true ， false 。</p></li><li><p>原始类型的列表可以用方括号（ [] ）制成。示例： [“foo”, “bar”, “baz”] 。</p></li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://runebook.dev/zh-CN/docs/terraform/-index-#Alicloud">https://runebook.dev/zh-CN/docs/terraform/-index-#Alicloud</a></li><li><a href="https://www.terraform.io/">https://www.terraform.io/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;简介：&quot;&gt;&lt;a href=&quot;#简介：&quot; class=&quot;headerlink&quot; title=&quot;简介：&quot;&gt;&lt;/a&gt;简介：&lt;/h2&gt;&lt;p&gt;Terraform是IT 基础架构自动化编排工具，它的口号是 “Write,Plan, and create Infrastruct</summary>
      
    
    
    
    <category term="Cloud" scheme="https://acodetailor.github.io/categories/Cloud/"/>
    
    
    <category term="terraform" scheme="https://acodetailor.github.io/tags/terraform/"/>
    
  </entry>
  
</feed>
