{"meta":{"title":"Sam","subtitle":"用我的双手，成就你的梦想。一库~","description":"杂记","author":"Sam","url":"https://acodetailor.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2021-03-30T07:24:39.640Z","updated":"2021-03-30T07:24:39.640Z","comments":false,"path":"/404.html","permalink":"https://acodetailor.github.io/404.html","excerpt":"","text":""},{"title":"书单","date":"2021-03-30T07:24:39.645Z","updated":"2021-03-30T07:24:39.644Z","comments":false,"path":"books/index.html","permalink":"https://acodetailor.github.io/books/index.html","excerpt":"","text":""},{"title":"关于","date":"2021-03-30T07:24:39.644Z","updated":"2021-03-30T07:24:39.643Z","comments":false,"path":"about/index.html","permalink":"https://acodetailor.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"分类","date":"2021-03-30T07:24:39.645Z","updated":"2021-03-30T07:24:39.645Z","comments":false,"path":"categories/index.html","permalink":"https://acodetailor.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2021-03-30T07:24:39.646Z","updated":"2021-03-30T07:24:39.646Z","comments":true,"path":"links/index.html","permalink":"https://acodetailor.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2021-03-30T07:24:39.647Z","updated":"2021-03-30T07:24:39.647Z","comments":false,"path":"repository/index.html","permalink":"https://acodetailor.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-03-30T07:24:39.648Z","updated":"2021-03-30T07:24:39.648Z","comments":false,"path":"tags/index.html","permalink":"https://acodetailor.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"java的OOM问题","slug":"java_oom","date":"2021-04-24T12:11:36.499Z","updated":"2021-04-24T12:42:39.334Z","comments":true,"path":"2021/04/24/java_oom/","link":"","permalink":"https://acodetailor.github.io/2021/04/24/java_oom/","excerpt":"","text":"一、一些概念JVM中的堆被划分为两个不同区域：新生代Young、老年代Old。新生代又划分为Eden(伊甸，标志新生)， Survivor0(s0)， Survivor(s1)。JVM中堆的GC分为：Minor GC 和 Full GC(又称为Major GC) 年轻代年轻代用于存放新创建的对象，存储大小默认为堆大小的1/15，特点是对象更替速度快，即短时间内产生大量的“死亡对象”-Xmn 可以设置年轻代为固定大小-XX:NewRatio 可以设置年轻代与老年代的大小比例年轻代使用复制-清除算法和并行收集器进行垃圾回收，对年轻代的垃圾回收称为初级回收（minor GC)minor GC 将年轻代分为三个区域，一个Eden, 两个大小相同的Survivor。应用程序只能同时使用一个Eden和一个活动Survivor, 另外一个Survivor为非活动Survivor（两个Survivor在活动与非活动间交替存在，即同一时刻只存在一个活动Survivor和一个非活动Survivor）。当发生 minor GC时：JVM执行下述操作 将程序挂起 将Eden和活动Survivor中的存活对象（存活对象指的是仍被引用的对象）复制到另一个非活动的Survivor中（记录对象被复制到另一个Survivor的次数，在此称为年龄数，每次复制+1） 清除Eden和活动Survivor中对象 将非活动Survivor标记为活动，将原来的活动Survivor标记为非活动上述即为一轮 minor GC 结束如此往复多次 minor GC后，将多次被复制的对象（高龄对象）移动到老年代中默认被移动到老年代的年龄为15，可以通过参数 -XX:MaxTenuring Threshold 来设置。当然，对于一些占用较大内存的对象，会被直接送入老年代 老年代老年代存储的是那些不会轻易“死掉”的对象，毕竟都在年轻代中熬出了头。在老年代发生的GC成为 Full GC 。Full GC 不会像 Minor GC那么频繁Full GC 采用 标记-清除算法 收集垃圾的时候会产生许多内存碎片（不连续的存储空间），因此此后若有较大的对象要进入老年代而无法找到适合的存储空间，就会提前触发一次GC收集，对内存空间进行整理 永久代永久代（Perm Gen）是JDK7中的特性，JDK8后被取消。永久区是JVM方法区的实现方式之一，JDK8起，被元空间（与堆不相连的本地空间）取而代之永久代存放的是应用元数据（应用中使用的类和方法），永久代中的对象在 Full GC 的时候进行垃圾回收 简单来讲，jvm的内存回收过程是这样的：对象在Eden Space创建，当Eden Space满了的时候，gc就把所有在Eden Space中的对象扫描一次，把所有有效的对象复制到第一个Survivor Space，同时把无效的对象所占用的空间释放。当Eden Space再次变满了的时候，就启动移动程序把Eden Space中有效的对象复制到第二个Survivor Space，同时，也将第一个Survivor Space中的有效对象复制到第二个Survivor Space。如果填充到第二个Survivor Space中的有效对象被第一个Survivor Space或Eden Space中的对象引用，那么这些对象就是长期存在的，此时这些对象将被复制到Permanent Generation。 若垃圾收集器依据这种小幅度的调整收集不能腾出足够的空间，就会运行Full GC，此时jvm gc停止所有在堆中运行的线程并执行清除动作。 二、优化配置-Xms 是指程序启动时初始内存大小（此值可以设置成与-Xmx相同，以避免每次GC完成后 JVM 内存重新分配）。默认为物理内存的1/64，最小为1M；可以指定单位，比如k、m，若不指定，则默认为字节。-Xmx 指程序运行时最大可用内存大小，程序运行中内存大于这个值会 OutOfMemory。默认为物理内存的1/4或者1G，最小为2M；单位与-Xms一致-Xmn 年轻代大小（整个JVM内存大小 = 年轻代 + 年老代 + 永久代）。-XX:NewRatio 年轻代与年老代的大小比例，-XX:NewRatio=4 设置为4，则年轻代与年老代所占比值为1：4。-XX:SurvivorRatio 年轻代中Eden区与Survivor区的大小比值，-XX:SurvivorRatio=4，设置为4，则两个Survivor区与一个Eden区的比值为 2:4-XX:MaxPermSize 设置永久代大小。-XX:MaxTenuringThreshold 设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。-Xss 设置每个线程的堆栈大小。默认为512k 三、容器化场景配置使用容器内存大小，避免Cgroup的oomJDK 8u131 在 JDK 9 中有一个特性，可以在 Docker 容器运行时能够检测到多少内存的能力。在容器内部运行 JVM，它在大多数情况下将如何默认最大堆为主机内存的1/4，而非容器内存的1/4。如果对 Java 容器中的jvm虚拟机不做任何限制，当我们同时运行几个 java 容器时，很容易导致服务器的内存耗尽、负载飙升而宕机；而如果我们对容器直接进行限制，就会导致内核在某个时候杀死jvm 容器而导致频繁重启。 12345$ docker run -m 100MB openjdk:8u121 java -XshowSettings:vm -versionVM settings: Max. Heap Size (Estimated): 444.50M Ergonomics Machine Class: server Using VM: OpenJDK 64-Bit Server VM 下面我们尝试 JDK 8u131 中的实验性参数 -XX:+UseCGroupMemoryLimitForHeap 12345678$ docker run -m 100MB openjdk:8u131 java \\ -XX:+UnlockExperimentalVMOptions \\ -XX:+UseCGroupMemoryLimitForHeap \\ -XshowSettings:vm -versionVM settings: Max. Heap Size (Estimated): 44.50M Ergonomics Machine Class: server Using VM: OpenJDK 64-Bit Server VM JVM能够检测容器只有100MB，并将最大堆设置为44M。 下面尝试一个更大的容器 12345678$ docker run -m 1GB openjdk:8u131 java \\ -XX:+UnlockExperimentalVMOptions \\ -XX:+UseCGroupMemoryLimitForHeap \\ -XshowSettings:vm -versionVM settings: Max. Heap Size (Estimated): 228.00M Ergonomics Machine Class: server Using VM: OpenJDK 64-Bit Server VM 嗯，现在容器有1GB，但JVM仅使用228M作为最大堆。 除了JVM正在容器中运行以外，我们是否还可以优化它呢？ 12345678$ docker run -m 1GB openjdk:8u131 java \\ -XX:+UnlockExperimentalVMOptions \\ -XX:+UseCGroupMemoryLimitForHeap \\ -XX:MaxRAMFraction=1 -XshowSettings:vm -versionVM settings: Max. Heap Size (Estimated): 910.50M Ergonomics Machine Class: server Using VM: OpenJDK 64-Bit Server VM 使用-XX:MaxRAMFraction 我们告诉JVM使用可用内存/ MaxRAMFraction作为最大堆。使用-XX:MaxRAMFraction=1我们几乎所有可用的内存作为最大堆。","categories":[{"name":"运维","slug":"运维","permalink":"https://acodetailor.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"oom","slug":"oom","permalink":"https://acodetailor.github.io/tags/oom/"}]},{"title":"Minikube搭建istio和Knative","slug":"install knative","date":"2021-04-19T09:26:51.731Z","updated":"2021-04-19T10:05:30.896Z","comments":true,"path":"2021/04/19/install knative/","link":"","permalink":"https://acodetailor.github.io/2021/04/19/install%20knative/","excerpt":"","text":"需要搭建一套knative的测试环境，但是没有测试集群可以用了，就用自己的电脑搭建了一个测试环境。搭建过程记录一下 环境信息os:MacDriver:VirtualBox 搭建minikube一条命令即可,可以指定cpu和内存–cpus int –memory int 1minikube start --vm-driver=virtualbox --image-repository=&#x27;registry.cn-hangzhou.aliyuncs.com/google_containers&#x27; minikube常用命令 123456789101112131415161718191. minikube start 启动minikube2. minikube dashboard 打开dashboard3. minikube version 查看minikube版本4. minikube status 查看集群状态5. minikube ip 显示虚拟机ip地址6. minikube stop 停止虚拟机7. minikube ssh ssh到虚拟机中8. minikube delete 删除虚拟机9. minikube logs 查看虚拟机日志10. minikube update-check 检查更新11. minikube node list[add|start|stop|delete] 对节点进行操作12. minikube mount 将指定的目录挂载到minikube13. minikube docker-env 配置环境以使用minikube的docker守护进程14. minikube podman-env 配置环境以使用minikube的Podman服务15. minikube cache 添加，删除，或推送一个本地映像到minikube16. minikube addons 启用或禁用一个minikube插件17. minikube config 修改持久化配置值18. minikube profile 获取或者列出当前的配置文件（集群）19. minikube update-context 在IP或者端口改变的情况下更新kubeconfig 安装成功后提示如下： 12345678910😄 Darwin 10.14.6 上的 minikube v1.8.2✨ 根据现有的配置文件使用 virtualbox 驱动程序✅ 正在使用镜像存储库 registry.cn-hangzhou.aliyuncs.com/google_containers💾 Downloading preloaded images tarball for k8s v1.17.3 ...⌛ 重新配置现有主机🏃 Using the running virtualbox &quot;minikube&quot; VM ...🐳 正在 Docker 19.03.6 中准备 Kubernetes v1.17.3…🚀 正在启动 Kubernetes ... 🌟 Enabling addons: default-storageclass, storage-provisioner🏄 完成！kubectl 已经配置至 &quot;minikube&quot; 搭建istio下载istio的包，然后根据提示配置环境变量，由于某些已知原因，可以配置host 1199.232.28.133 raw.githubusercontent.com 1curl -L https://istio.io/downloadIstio | ISTIO_VERSION=1.9.1 TARGET_ARCH=x86_64 sh - 安装命令：根据需要选择合适的profile 12istioctl manifest apply --set profile=demo //使用这条命令安装失败了。istioctl install --set profile=demo -y 追加部署addons 12cd istio-1.9.1kc --context=minikube apply -f samples/addons -n istio-system 搭建knativeknative搭建比较简单，可以手动安装，再麻烦一点，可以自己下载yaml手动执行，serving和eventing一共四个yaml 1234serving-crdsserving-coreeventing-crdseventing-core 1kubectl apply --filename &quot;https://github.com/knative/serving/releases/download/v0.17.0/serving-crds.yaml&quot; 比较麻烦的是镜像，国内无法直接下载到，可以手动下载后，使用minikube cache 添加到minikube的节点上。 结果","categories":[{"name":"k8s","slug":"k8s","permalink":"https://acodetailor.github.io/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://acodetailor.github.io/tags/k8s/"}]},{"title":"记一次OOM的问题排查","slug":"ops-oom","date":"2021-04-12T13:03:40.025Z","updated":"2021-04-12T13:34:52.892Z","comments":true,"path":"2021/04/12/ops-oom/","link":"","permalink":"https://acodetailor.github.io/2021/04/12/ops-oom/","excerpt":"","text":"一、问题现象 三天前，业务的pod重启了，业务想知道具体原因。 二、排查记录 首先排查kubelet日志，蛋疼的是期间业务手动重启了几次，导致不知道pod重启时所在的节点。一个个节点排查kubelet的日志（不知道后续有没有好的方法），找到节点发现日志如下： kubelet执行PLEG时发现容器挂掉了，直接给拉起了，就是业务前台发现的重启事件。 再排查业务日志，发现只有Killed,八成是OOM了。日志截图如下： 下一步排查内核日志，kerenal。发现确实是OOM了。截图如下: 然后问题来了，我们的监控发现并没有达到内存的上限，但是cgroup确实达到了上限。真是让人头大啊。 三、几个命令12zgrep &quot;&quot; *.gzjournalctl --since &#x27;2021-04-09 22:00&#x27; 四、引申问题 1、cgroup的机制 2、java的内存机制","categories":[{"name":"运维","slug":"运维","permalink":"https://acodetailor.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"oom","slug":"oom","permalink":"https://acodetailor.github.io/tags/oom/"}]},{"title":"","slug":"TCP","date":"2021-04-09T06:37:26.865Z","updated":"2021-04-09T06:37:26.865Z","comments":true,"path":"2021/04/09/TCP/","link":"","permalink":"https://acodetailor.github.io/2021/04/09/TCP/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"","slug":"Iptabels And Ipvs","date":"2021-04-09T06:37:13.851Z","updated":"2021-04-09T06:37:13.851Z","comments":true,"path":"2021/04/09/Iptabels And Ipvs/","link":"","permalink":"https://acodetailor.github.io/2021/04/09/Iptabels%20And%20Ipvs/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"terraform cloud CLI","slug":"terraform_cloud","date":"2021-04-07T02:02:39.990Z","updated":"2021-04-07T05:41:50.275Z","comments":true,"path":"2021/04/07/terraform_cloud/","link":"","permalink":"https://acodetailor.github.io/2021/04/07/terraform_cloud/","excerpt":"","text":"一、简介 terraform自身提供可一个机制（类似CI/CD的流水线），可以配置自己的git库，根据git库文件内容的变化，执行plan、apply，也可以手动执行。以及配置变量文件、环境变量、state文件统一存储等等功能。 二、对比1、使用terraform二进制。 需要下载provider(terraform init) 编写tf文件，backend存储。也需要统一的配置管理。 每次手动触发。 2、使用Cloud CLI。 不需要准备provider 统一的配置管理 git push后即触发 terraform 三、栗子1、创建组织 terraform网站创建即可。 https://app.terraform.io2、配置git库 可以使用个人的git库，配置Oauth权限。根据提示 在github-&gt;setting-&gt;developer settings-&gt; oauth apps申请配置即可。 3、选择工程 git新建一个工程，然后再terraform处选择该工程。 4、测试 执行Run即可，每次修改都会触发 plan,然后需要手动执行apply。 5、结果","categories":[{"name":"terraform","slug":"terraform","permalink":"https://acodetailor.github.io/categories/terraform/"}],"tags":[{"name":"terraform","slug":"terraform","permalink":"https://acodetailor.github.io/tags/terraform/"}]},{"title":"Kubernetes CRD -- kubebuilder搭建","slug":"k8s_crd","date":"2021-04-02T02:17:18.350Z","updated":"2021-04-02T03:53:26.061Z","comments":true,"path":"2021/04/02/k8s_crd/","link":"","permalink":"https://acodetailor.github.io/2021/04/02/k8s_crd/","excerpt":"","text":"概念官方解释：CustomResourceDefinition API 资源允许你定义定制资源。 定义 CRD 对象的操作会使用你所设定的名字和模式定义（Schema）创建一个新的定制资源， Kubernetes API 负责为你的定制资源提供存储和访问服务。 CRD 对象的名称必须是合法的 DNS 子域名。 DNS子域名规则如下： 不能超过253个字符 只能包含小写字母、数字，以及’-‘ 和 ‘.’ 须以字母数字开头 须以字母数字结尾 简单来说，你可以定义像k8s原生资源如deployment、service一样定义自己的资源，而k8s会为你提供存储（ETCD）,访问（kube-apiserver）。 脚手架kubebuilder 和 operator sdk, 个人只使用过kubebuilder。 安装kubebuilder依赖1、docker2、go 建议版本在1.12以上，支持 go mod3、kustomize 代理配置配置一下 终端代理，因为初始化时会拉去go的依赖包。go 1.12之下开启 go module 12export GOPROXY=https://goproxy.ioexport GO111MODULE=on 安装一、安装kubebuilder执行如下命令。（如果curl下载失败，大概率是网络原因，可以手动下载，解压到指定目录）。 12345os= $(go env GOOS)arch=$(go env GOARCH)curl -L https://go.kubebuilder.io/dl/2.3.1/$&#123;os&#125;/$&#123;arch&#125; | tar -xz -C /tmp/sudo mv /tmp/kubebuilder_2.3.1_$&#123;os&#125;_$&#123;arch&#125; /usr/local/kubebuilderexport PATH=$PATH:/usr/local/kubebuilder/bin 二、安装kustomize 1brew install kustomize 三、安装完成后查看版本信息 12345$ kubebuilder versionVersion: version.Version&#123;KubeBuilderVersion:&quot;2.3.1&quot;, KubernetesVendor:&quot;1.16.4&quot;, GitCommit:&quot;8b53abeb4280186e494b726edf8f54ca7aa64a49&quot;, BuildDate:&quot;2020-03-26T16:42:00Z&quot;, GoOs:&quot;unknown&quot;, GoArch:&quot;unknown&quot;&#125;# sam @ MacBook-Pro-2 in ~/tf/alitest [10:45:37]$ kustomize version&#123;Version:kustomize/v3.8.2 GitCommit:e2973f6ecc9be6187cfd5ecf5e180f842249b3c6 BuildDate:2020-09-02T07:01:55+01:00 GoOs:darwin GoArch:amd64&#125; 四、初始化工程 12kubebuilder init --domain my.crd.com //初始化工程kubebuilder create api --group custom --version v1 --kind Unit //生成脚手架代码 group: 比如资源文件的apps/v1, apps即为分组，还有其他extensions、cores等。 version: 顾名思义、v1即为版本。 kind: API “顶级”资源对象的类型，每个资源对象都需要 Kind 来区分它自身代表的资源类型。比如 pod,deployment. resource: 通过 HTTP 协议以 JSON 格式发送或者读取的资源展现形式，可以以单个资源对象展现。 GVK(group、version、kind):同 Kind 不止可以出现在同一分组的不同版本中，如 apps/v1beta1 与 apps/v1，它还可能出现在不同的分组中，例如 Deployment 开始以 alpha 的特性出现在 extensions 分组，GA 之后被推进到 apps 组，所以为了严格区分不同的 Kind，需要组合 API Group、API Version 与 Kind 成为 GVK。 GVR(group、version、resource):GVR 常用于组合成 RESTful API 请求路径。例如，针对应用程序 v1 部署的 RESTful API 请求如下所示： 1GET /apis/apps/v1/namespaces/&#123;namespace&#125;/deployments/&#123;name&#125;","categories":[{"name":"k8s","slug":"k8s","permalink":"https://acodetailor.github.io/categories/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://acodetailor.github.io/tags/k8s/"}]},{"title":"Terraform介绍","slug":"terraform","date":"2021-03-30T02:38:39.714Z","updated":"2021-04-01T08:23:43.207Z","comments":true,"path":"2021/03/30/terraform/","link":"","permalink":"https://acodetailor.github.io/2021/03/30/terraform/","excerpt":"","text":"简介：Terraform是IT 基础架构自动化编排工具，它的口号是 “Write,Plan, and create Infrastructure as Code”, 基础架构即代码。 怎么理解这句话，我们先假设在没有Terraform的年代我们是怎么操作云服务。 方式一：直接登入到云平台的管控页面，人工点击按钮、键盘敲入输入参数的方式来操作，这种方式对于单个或几个云服务器还可以维护的过来，但是当云服务规模达到几十几百甚至上千以后，明显这种方式对于人力来说变得不再现实，而且容易误操作。 方式二：云平台提供了各种SDK，将对云服务的操作拆解成一个个的API供使用厂商通过代码来调用。这种方式明显好于方式一，使大批量操作变得可能，而且代码测试通过后可以避免人为误操作。但是随之带来的问题是厂商们需要专业的开发人员（Java、Python、Php、Ruby等），而且对复杂云平台的操作需要写大量的代码。 方式三：云平台提供了命令行操作云服务的工具，例如AWS CLI，这样租户厂商不再需要软件开发人员就可以实现对平台的命令操作。命令就像Sql一样，使用增删改查等操作元素来管理云。 方式四：Terraform主角登场，如果说方式三中CLI是命令式操作，需要明确的告知云服务本次操作是查询、新增、修改、还是删除，那么Terraform就是目的式操作，在本地维护了一份云服务状态的模板，模板编排成什么样子的，云服务就是什么样子的。对比方式三的优势是我们只需要专注于编排结果即可，不需要关心用什么命令去操作。 Terraform的意义在于，通过同一套规则和命令来操作不同的云平台（包括私有云）。 Terraform知识准备：核心文件有2个，一个是编排文件，一个是状态文件 main.tf文件：是业务编排的主文件，定制了一系列的编排规则，后面会有详细介绍。 terraform.tfstate：本地状态文件，相当于本地的云服务状态的备份，会影响terraform的执行计划。 如果本地状态与云服务状态不一样时会怎样？ 这个大家不需要担心，前面介绍过Terraform是目的式的编排，会按照预设结果完成编排并最终同步更新本地文件。 Provider：Terraform定制的一套接口，跟OpenStack里Dirver、Java里Interface的概念是一样的，阿里云、AWS、私有云等如果想接入进来被Terraform编排和管理就要实现一套Provider，而这些实现对于Terraform的顶层使用者来说是无感知的。 Module：可以理解为provider的集合，完成一个完整的功能。 相关命令：初始化初始化本地环境，下载provider,校验terraform版本等. 12$ terraform init //自动下载最新的provider$ terraform init -plugin-dir //指定provider目录 plan比较云端资源和本地state资源. 1$ terraform plan 部署将修改部署到云端资源. 1$ terraform apply 删除将云端资源删除. 1$ terraform destory Example创建阿里云用户组、资源组并且配置只读权限。注: alicloud : 阿里云provider名字，不能修改。 1234567891011121314151617181920212223242526provider &quot;alicloud&quot; &#123; access_key = &quot;*******************&quot; secret_key = &quot;*************************&quot; region = &quot;cn-beijing&quot; &#125; resource &quot;alicloud_ram_group&quot; &quot;group&quot; &#123; name = &quot;test_group_1000&quot; force = true &#125; resource &quot;alicloud_ram_group_policy_attachment&quot; &quot;attach&quot; &#123; policy_name = &quot;ReadOnlyAccess&quot; policy_type = &quot;System&quot; group_name = alicloud_ram_group.group.name &#125; resource &quot;alicloud_resource_manager_resource_group&quot; &quot;example&quot; &#123; resource_group_name = &quot;tftest01&quot; display_name = &quot;tftest01&quot; &#125; data &quot;alicloud_account&quot; &quot;example&quot; &#123;&#125; resource &quot;alicloud_resource_manager_policy_attachment&quot; &quot;example&quot; &#123; policy_name = &quot;ReadOnlyAccess&quot; policy_type = &quot;System&quot; principal_name = format(&quot;%s@group.%s.onaliyun.com&quot;, alicloud_ram_group.group.name, data.alicloud_account.example.id) principal_type = &quot;IMSGroup&quot; resource_group_id = alicloud_resource_manager_resource_group.example.id &#125; 其他1、配置terraform自动补全 1$ terraform -install-autocomplete 2、查看terraform的日志 12$ export TF_LOG=TRACE$ export TF_LOG_PATH=/var/log/terraform.log 3、terraform 通过配置文件或者环境变量进行配置文件目录(自己创建) 1$ $HOME/.terraformrc 环境变量 1$ os.Setenv(&quot;TF_PLUGIN_CACHE_DIR&quot;, &quot;/tmp/provider&quot;) // add provider cache state文件存储，支持consul、oss等12345678910111213terraform &#123; backend &quot;consul&quot; &#123; address = &quot;consul.example.com&quot; scheme = &quot;https&quot; path = &quot;full/path&quot; &#125;&#125;data &quot;terraform_remote_state&quot; &quot;foo&quot; &#123; backend = &quot;consul&quot; config = &#123; path = &quot;full/path&quot; &#125;&#125; 参考： https://theithollow.com/2018/05/21/using-hashicorp-consul-to-store-terraform-state/ 语法 单行注释以 # 开头 多行注释用 /* 和 */ 换行 值使用 key = value 的语法分配（空格无关紧要）。该值可以是任何原语（字符串，数字，布尔值），列表或映射。 字符串为双引号。 字符串可以使用 ${} 包装的语法对其他值进行插值，例如 ${var.foo} 。此处记录了完整的内插语法。 多行字符串可以使用外壳样式的“ here doc”语法，该字符串以类似 &lt;&lt;EOF 的标记开头，然后以 EOF 结尾。字符串和结束标志的线路必须不能缩进。 假定数字以10为底。如果为数字加上 0x 前缀，则将其视为十六进制数字。 布尔值： true ， false 。 原始类型的列表可以用方括号（ [] ）制成。示例： [“foo”, “bar”, “baz”] 。 参考 https://runebook.dev/zh-CN/docs/terraform/-index-#Alicloud https://www.terraform.io/","categories":[{"name":"Cloud","slug":"Cloud","permalink":"https://acodetailor.github.io/categories/Cloud/"}],"tags":[{"name":"terraform","slug":"terraform","permalink":"https://acodetailor.github.io/tags/terraform/"}]}],"categories":[{"name":"运维","slug":"运维","permalink":"https://acodetailor.github.io/categories/%E8%BF%90%E7%BB%B4/"},{"name":"k8s","slug":"k8s","permalink":"https://acodetailor.github.io/categories/k8s/"},{"name":"terraform","slug":"terraform","permalink":"https://acodetailor.github.io/categories/terraform/"},{"name":"Cloud","slug":"Cloud","permalink":"https://acodetailor.github.io/categories/Cloud/"}],"tags":[{"name":"oom","slug":"oom","permalink":"https://acodetailor.github.io/tags/oom/"},{"name":"k8s","slug":"k8s","permalink":"https://acodetailor.github.io/tags/k8s/"},{"name":"terraform","slug":"terraform","permalink":"https://acodetailor.github.io/tags/terraform/"}]}